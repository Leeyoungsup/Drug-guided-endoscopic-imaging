{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.utils\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "import os\n",
    "import torchmetrics\n",
    "import timm\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"2\" \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=4\n",
    "image_count=50\n",
    "img_size=256\n",
    "tf = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1193/1193 [01:57<00:00, 10.14it/s]\n",
      "100%|██████████| 184/184 [00:16<00:00, 10.83it/s]\n",
      "100%|██████████| 80/80 [00:07<00:00, 10.81it/s]\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, id,image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "\n",
    "        self.label = label_list\n",
    "        self.id=id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_tensor=self.id[idx]\n",
    "        image_tensor = self.img_path[idx]\n",
    "    \n",
    "        label_tensor =  self.label[idx]\n",
    "        return image_tensor, label_tensor\n",
    "\n",
    "\n",
    "train_data=pd.read_csv('../../data/mteg_data/internal/train_label.csv') \n",
    "file_path='../../data/mteg_data/internal/train/'\n",
    "train_image_list=[]\n",
    "for i in range(len(train_data)):\n",
    "    file_name=train_data.loc[i]['File Name']\n",
    "    id=file_name[:file_name.find('_')]\n",
    "    train_image_list.append(file_path+id)\n",
    "label_data=pd.read_csv('../../data/mteg_data/internal/label.csv')  \n",
    "train_label_list=[]\n",
    "train_id_list=[]\n",
    "train_image_tensor = torch.empty((len(train_image_list),image_count,3, img_size, img_size))\n",
    "for i in tqdm(range(len(train_image_list))):\n",
    "    folder_name=os.path.basename(train_image_list[i])\n",
    "    dst_label=label_data.loc[label_data['일련번호']==int(folder_name[:-1])]\n",
    "    dst_label=dst_label.loc[dst_label['구분값']==int(folder_name[-1])].reset_index()\n",
    "    label=int(dst_label.loc[0]['OTE 원인'])\n",
    "    train_id_list.append(folder_name)\n",
    "    train_label_list.append(label-1) \n",
    "    image_file_list = glob(train_image_list[i]+'/*.jpg')\n",
    "    if len(image_file_list)>image_count:\n",
    "        image_index = torch.randint(low=0, high=len(\n",
    "            image_file_list)-image_count, size=(1,))\n",
    "        count = 0\n",
    "        for index in range(image_count):\n",
    "            image = 1-tf(Image.open(image_file_list[index]).resize((img_size,img_size)))\n",
    "            train_image_tensor[i,count] = image\n",
    "            count += 1\n",
    "    else:\n",
    "        count = 0\n",
    "        for index in range(len(image_file_list)):\n",
    "            image = 1-tf(Image.open(image_file_list[index]).resize((img_size,img_size)))\n",
    "            train_image_tensor[i,count] = image\n",
    "            count += 1\n",
    "        for j in range(image_count-count-1):\n",
    "            image = 1-tf(Image.open(image_file_list[j]).resize((img_size,img_size)))\n",
    "            train_image_tensor[i,count] = image\n",
    "            count += 1\n",
    "            \n",
    "val_data=pd.read_csv('../../data/mteg_data/internal/val_label.csv') \n",
    "file_path='../../data/mteg_data/internal/val/'\n",
    "val_image_list=[]\n",
    "for i in range(len(val_data)):\n",
    "    file_name=val_data.loc[i]['File Name']\n",
    "    id=file_name[:file_name.find('_')]\n",
    "    val_image_list.append(file_path+id)\n",
    "label_data=pd.read_csv('../../data/mteg_data/internal/label.csv')  \n",
    "val_label_list=[]\n",
    "val_id_list=[]\n",
    "val_image_tensor = torch.empty((len(val_image_list),image_count,3, img_size, img_size))\n",
    "for i in tqdm(range(len(val_image_list))):\n",
    "    folder_name=os.path.basename(val_image_list[i])\n",
    "    dst_label=label_data.loc[label_data['일련번호']==int(folder_name[:-1])]\n",
    "    dst_label=dst_label.loc[dst_label['구분값']==int(folder_name[-1])].reset_index()\n",
    "    label=int(dst_label.loc[0]['OTE 원인'])\n",
    "    val_id_list.append(folder_name)\n",
    "    val_label_list.append(label-1) \n",
    "    image_file_list = glob(val_image_list[i]+'/*.jpg')\n",
    "    if len(image_file_list)>image_count:\n",
    "        image_index = torch.randint(low=0, high=len(\n",
    "            image_file_list)-image_count, size=(1,))\n",
    "        count = 0\n",
    "        for index in range(image_count):\n",
    "            image = 1-tf(Image.open(image_file_list[index]).resize((img_size,img_size)))\n",
    "            val_image_tensor[i,count] = image\n",
    "            count += 1\n",
    "    else:\n",
    "        count = 0\n",
    "        for index in range(len(image_file_list)):\n",
    "            image = 1-tf(Image.open(image_file_list[index]).resize((img_size,img_size)))\n",
    "            val_image_tensor[i,count] = image\n",
    "            count += 1\n",
    "        for j in range(image_count-count):\n",
    "            image = 1-tf(Image.open(image_file_list[j]).resize((img_size,img_size)))\n",
    "            val_image_tensor[i,count] = image\n",
    "            count += 1\n",
    "\n",
    "test_data=pd.read_csv('../../data/mteg_data/internal/test_label.csv') \n",
    "file_path='../../data/mteg_data/internal/test/'\n",
    "test_image_list=[]\n",
    "for i in range(len(test_data)):\n",
    "    file_name=test_data.loc[i]['File Name']\n",
    "    id=file_name[:file_name.find('_')]\n",
    "    test_image_list.append(file_path+id)\n",
    "label_data=pd.read_csv('../../data/mteg_data/internal/label.csv')  \n",
    "test_label_list=[]\n",
    "test_id_list=[]\n",
    "test_image_tensor = torch.empty((len(test_image_list),image_count,3, img_size, img_size))\n",
    "for i in tqdm(range(len(test_image_list))):\n",
    "    folder_name=os.path.basename(test_image_list[i])\n",
    "    dst_label=label_data.loc[label_data['일련번호']==int(folder_name[:-1])]\n",
    "    dst_label=dst_label.loc[dst_label['구분값']==int(folder_name[-1])].reset_index()\n",
    "    label=int(dst_label.loc[0]['OTE 원인'])\n",
    "    test_id_list.append(folder_name)\n",
    "    test_label_list.append(label-1) \n",
    "    image_file_list = glob(test_image_list[i]+'/*.jpg')\n",
    "    if len(image_file_list)>image_count:\n",
    "        image_index = torch.randint(low=0, high=len(\n",
    "            image_file_list)-image_count, size=(1,))\n",
    "        count = 0\n",
    "        for index in range(image_count):\n",
    "            image = 1-tf(Image.open(image_file_list[index]).resize((img_size,img_size)))\n",
    "            test_image_tensor[i,count] = image\n",
    "            count += 1\n",
    "    else:\n",
    "        count = 0\n",
    "        for index in range(len(image_file_list)):\n",
    "            image = 1-tf(Image.open(image_file_list[index]).resize((img_size,img_size)))\n",
    "            test_image_tensor[i,count] = image\n",
    "            count += 1\n",
    "        for j in range(image_count-count):\n",
    "            image = 1-tf(Image.open(image_file_list[j]).resize((img_size,img_size)))\n",
    "            test_image_tensor[i,count] = image\n",
    "            count += 1\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_id_list,train_image_tensor, F.one_hot(torch.tensor(train_label_list).to(torch.int64)))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_dataset = CustomDataset(val_id_list,val_image_tensor, F.one_hot(torch.tensor(val_label_list).to(torch.int64)))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataset = CustomDataset(test_id_list,test_image_tensor, F.one_hot(torch.tensor(test_label_list).to(torch.int64)))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "AttentionMILModel                                       [4, 3]                    --\n",
       "├─FeatureExtractor: 1-1                                 [200, 1408]               --\n",
       "│    └─Sequential: 2-1                                  [200, 1408]               --\n",
       "│    │    └─Conv2d: 3-1                                 [200, 32, 128, 128]       864\n",
       "│    │    └─BatchNormAct2d: 3-2                         [200, 32, 128, 128]       64\n",
       "│    │    └─Sequential: 3-3                             [200, 352, 8, 8]          7,201,634\n",
       "│    │    └─Conv2d: 3-4                                 [200, 1408, 8, 8]         495,616\n",
       "│    │    └─BatchNormAct2d: 3-5                         [200, 1408, 8, 8]         2,816\n",
       "│    │    └─SelectAdaptivePool2d: 3-6                   [200, 1408]               --\n",
       "├─Sequential: 1-2                                       [4, 50, 1]                --\n",
       "│    └─Linear: 2-2                                      [4, 50, 128]              180,352\n",
       "│    └─Tanh: 2-3                                        [4, 50, 128]              --\n",
       "│    └─Linear: 2-4                                      [4, 50, 1]                129\n",
       "├─Dropout: 1-3                                          [4, 1408]                 --\n",
       "├─Linear: 1-4                                           [4, 3]                    4,227\n",
       "=========================================================================================================\n",
       "Total params: 7,885,702\n",
       "Trainable params: 7,885,702\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 171.69\n",
       "=========================================================================================================\n",
       "Input size (MB): 157.29\n",
       "Forward/backward pass size (MB): 20488.48\n",
       "Params size (MB): 31.27\n",
       "Estimated Total Size (MB): 20677.04\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"Feature extoractor block\"\"\"\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        cnn1= timm.create_model('efficientnet_b2', pretrained=True)\n",
    "        self.feature_ex = nn.Sequential(*list(cnn1.children())[:-1])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        features = self.feature_ex(inputs)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "class AttentionMILModel(nn.Module):\n",
    "    def __init__(self, num_classes, image_feature_dim,feature_extractor_scale1: FeatureExtractor):\n",
    "        super(AttentionMILModel, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.image_feature_dim = image_feature_dim\n",
    "\n",
    "        # Remove the classification head of the CNN model\n",
    "        self.feature_extractor = feature_extractor_scale1\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(image_feature_dim, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        # Classification layer\n",
    "        self.classification_layer = nn.Linear(image_feature_dim, num_classes)\n",
    "        self.dropout=torch.nn.Dropout(0.2)\n",
    "    def forward(self, inputs):\n",
    "        batch_size, num_tiles, channels, height, width = inputs.size()\n",
    "        \n",
    "        # Flatten the inputs\n",
    "        inputs = inputs.view(-1, channels, height, width)\n",
    "        \n",
    "        # Feature extraction using the pre-trained CNN\n",
    "        features = self.feature_extractor(inputs)  # Shape: (batch_size * num_tiles, 2048, 1, 1)\n",
    "        \n",
    "        # Reshape features\n",
    "        features = features.view(batch_size, num_tiles, -1)  # Shape: (batch_size, num_tiles, 2048)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attention_weights = self.attention(features)  # Shape: (batch_size, num_tiles, 1)\n",
    "        attention_weights = F.softmax(attention_weights, dim=1)  # Normalize attention weights\n",
    "        \n",
    "        # Apply attention weights to features\n",
    "        attended_features = torch.sum(features * attention_weights, dim=1)  # Shape: (batch_size, 2048)\n",
    "        attended_features=self.dropout(attended_features)\n",
    "        attended_features=F.relu(attended_features)\n",
    "        # Classification layer\n",
    "        logits = self.classification_layer(attended_features)  # Shape: (batch_size, num_classes)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "        self.defaults.update(self.base_optimizer.defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "                    torch.stack([\n",
    "                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                        for group in self.param_groups for p in group[\"params\"]\n",
    "                        if p.grad is not None\n",
    "                    ]),\n",
    "                    p=2\n",
    "               )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups\n",
    "        \n",
    "def disable_running_stats(model):\n",
    "    def _disable(module):\n",
    "        if isinstance(module, _BatchNorm):\n",
    "            module.backup_momentum = module.momentum\n",
    "            module.momentum = 0\n",
    "\n",
    "    model.apply(_disable)\n",
    "\n",
    "def enable_running_stats(model):\n",
    "    def _enable(module):\n",
    "        if isinstance(module, _BatchNorm) and hasattr(module, \"backup_momentum\"):\n",
    "            module.momentum = module.backup_momentum\n",
    "            \n",
    "import transformers\n",
    "Feature_Extractor=FeatureExtractor()\n",
    "model = AttentionMILModel(3,1408,Feature_Extractor)\n",
    "model = model.to(device)\n",
    "class_counts = [train_label_list.count(0), train_label_list.count(1), train_label_list.count(2)]\n",
    "class_weights = [1 - (x / sum(class_counts)) for x in class_counts]\n",
    "class_weights =  torch.FloatTensor(class_weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\",num_classes=3).to(device)\n",
    "base_optimizer = torch.optim.SGD\n",
    "optimizer = SAM(model.parameters(), base_optimizer, lr=2e-2, momentum=0.9)\n",
    "optimizer1 = torch.optim.NAdam(model.parameters(), lr=2e-5)\n",
    "summary(model,(batch_size,image_count,3,img_size,img_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[deeplearning Start]\n",
      "deeplearning Start Time : 2024-5-8 16:54:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/300 Step: 299 loss : 1.0847 accuracy: 0.4144: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 1/300 Step: 299 loss : 1.0276 accuracy: 0.4457: 100%|██████████| 46/46 [00:06<00:00,  7.32it/s]\n",
      "epoch: 2/300 Step: 299 loss : 1.0468 accuracy: 0.4782: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 2/300 Step: 299 loss : 1.0038 accuracy: 0.5217: 100%|██████████| 46/46 [00:06<00:00,  6.71it/s]\n",
      "epoch: 3/300 Step: 299 loss : 1.0182 accuracy: 0.5168: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 3/300 Step: 299 loss : 1.0546 accuracy: 0.3859: 100%|██████████| 46/46 [00:06<00:00,  7.09it/s]\n",
      "epoch: 4/300 Step: 299 loss : 0.9884 accuracy: 0.5503: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 4/300 Step: 299 loss : 1.0306 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  7.12it/s]\n",
      "epoch: 5/300 Step: 299 loss : 0.9663 accuracy: 0.5789: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 5/300 Step: 299 loss : 1.0515 accuracy: 0.4022: 100%|██████████| 46/46 [00:07<00:00,  6.33it/s]\n",
      "epoch: 6/300 Step: 299 loss : 0.9292 accuracy: 0.6284: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 6/300 Step: 299 loss : 1.0002 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.97it/s]\n",
      "epoch: 7/300 Step: 299 loss : 0.8986 accuracy: 0.6535: 100%|██████████| 298/298 [04:05<00:00,  1.22it/s]\n",
      "val_epoch: 7/300 Step: 299 loss : 1.0144 accuracy: 0.5000: 100%|██████████| 46/46 [00:06<00:00,  7.00it/s]\n",
      "epoch: 8/300 Step: 299 loss : 0.8730 accuracy: 0.6888: 100%|██████████| 298/298 [04:05<00:00,  1.22it/s]\n",
      "val_epoch: 8/300 Step: 299 loss : 1.0823 accuracy: 0.4511: 100%|██████████| 46/46 [00:06<00:00,  6.96it/s]\n",
      "epoch: 9/300 Step: 299 loss : 0.8271 accuracy: 0.7273: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 9/300 Step: 299 loss : 0.9699 accuracy: 0.5870: 100%|██████████| 46/46 [00:06<00:00,  6.96it/s]\n",
      "epoch: 10/300 Step: 299 loss : 0.8311 accuracy: 0.7215: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 10/300 Step: 299 loss : 1.0954 accuracy: 0.4511: 100%|██████████| 46/46 [00:06<00:00,  6.91it/s]\n",
      "epoch: 11/300 Step: 299 loss : 0.7902 accuracy: 0.7760: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 11/300 Step: 299 loss : 1.0496 accuracy: 0.5109: 100%|██████████| 46/46 [00:06<00:00,  6.80it/s]\n",
      "epoch: 12/300 Step: 299 loss : 0.7637 accuracy: 0.8020: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 12/300 Step: 299 loss : 1.0342 accuracy: 0.5217: 100%|██████████| 46/46 [00:06<00:00,  6.98it/s]\n",
      "epoch: 13/300 Step: 299 loss : 0.7462 accuracy: 0.8138: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 13/300 Step: 299 loss : 1.0385 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.69it/s]\n",
      "epoch: 14/300 Step: 299 loss : 0.7458 accuracy: 0.8062: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 14/300 Step: 299 loss : 1.0490 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.62it/s]\n",
      "epoch: 15/300 Step: 299 loss : 0.7272 accuracy: 0.8280: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 15/300 Step: 299 loss : 1.0414 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.67it/s]\n",
      "epoch: 16/300 Step: 299 loss : 0.7108 accuracy: 0.8440: 100%|██████████| 298/298 [04:05<00:00,  1.22it/s]\n",
      "val_epoch: 16/300 Step: 299 loss : 1.0445 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  7.07it/s]\n",
      "epoch: 17/300 Step: 299 loss : 0.6927 accuracy: 0.8633: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 17/300 Step: 299 loss : 1.0449 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.67it/s]\n",
      "epoch: 18/300 Step: 299 loss : 0.6930 accuracy: 0.8624: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 18/300 Step: 299 loss : 1.0761 accuracy: 0.4565: 100%|██████████| 46/46 [00:06<00:00,  6.73it/s]\n",
      "epoch: 19/300 Step: 299 loss : 0.6754 accuracy: 0.8809: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 19/300 Step: 299 loss : 1.0462 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.90it/s]\n",
      "epoch: 20/300 Step: 299 loss : 0.6678 accuracy: 0.8876: 100%|██████████| 298/298 [04:05<00:00,  1.22it/s]\n",
      "val_epoch: 20/300 Step: 299 loss : 1.0512 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.83it/s]\n",
      "epoch: 21/300 Step: 299 loss : 0.6566 accuracy: 0.9018: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 21/300 Step: 299 loss : 1.0527 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.92it/s]\n",
      "epoch: 22/300 Step: 299 loss : 0.6396 accuracy: 0.9144: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 22/300 Step: 299 loss : 1.0474 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.97it/s]\n",
      "epoch: 23/300 Step: 299 loss : 0.6463 accuracy: 0.9086: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 23/300 Step: 299 loss : 1.0459 accuracy: 0.5163: 100%|██████████| 46/46 [00:07<00:00,  6.53it/s]\n",
      "epoch: 24/300 Step: 299 loss : 0.6379 accuracy: 0.9178: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 24/300 Step: 299 loss : 1.0458 accuracy: 0.5163: 100%|██████████| 46/46 [00:07<00:00,  6.47it/s]\n",
      "epoch: 25/300 Step: 299 loss : 0.6240 accuracy: 0.9354: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 25/300 Step: 299 loss : 1.0464 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.71it/s]\n",
      "epoch: 26/300 Step: 299 loss : 0.6177 accuracy: 0.9396: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 26/300 Step: 299 loss : 1.0458 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.76it/s]\n",
      "epoch: 27/300 Step: 299 loss : 0.6215 accuracy: 0.9304: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 27/300 Step: 299 loss : 1.0461 accuracy: 0.5163: 100%|██████████| 46/46 [00:07<00:00,  6.53it/s]\n",
      "epoch: 28/300 Step: 299 loss : 0.6297 accuracy: 0.9253: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 28/300 Step: 299 loss : 1.0321 accuracy: 0.5272: 100%|██████████| 46/46 [00:06<00:00,  7.03it/s]\n",
      "epoch: 29/300 Step: 299 loss : 0.6326 accuracy: 0.9237: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 29/300 Step: 299 loss : 1.0478 accuracy: 0.5163: 100%|██████████| 46/46 [00:07<00:00,  6.49it/s]\n",
      "epoch: 30/300 Step: 299 loss : 0.6198 accuracy: 0.9312: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 30/300 Step: 299 loss : 1.0488 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.97it/s]\n",
      "epoch: 31/300 Step: 299 loss : 0.6162 accuracy: 0.9404: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 31/300 Step: 299 loss : 1.0449 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.67it/s]\n",
      "epoch: 32/300 Step: 299 loss : 0.6135 accuracy: 0.9388: 100%|██████████| 298/298 [04:08<00:00,  1.20it/s]\n",
      "val_epoch: 32/300 Step: 299 loss : 1.0333 accuracy: 0.5272: 100%|██████████| 46/46 [00:06<00:00,  6.86it/s]\n",
      "epoch: 33/300 Step: 299 loss : 0.6003 accuracy: 0.9547: 100%|██████████| 298/298 [04:08<00:00,  1.20it/s]\n",
      "val_epoch: 33/300 Step: 299 loss : 1.0472 accuracy: 0.5163: 100%|██████████| 46/46 [00:07<00:00,  6.43it/s]\n",
      "epoch: 34/300 Step: 299 loss : 0.6172 accuracy: 0.9371: 100%|██████████| 298/298 [04:07<00:00,  1.20it/s]\n",
      "val_epoch: 34/300 Step: 299 loss : 1.0495 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.60it/s]\n",
      "epoch: 35/300 Step: 299 loss : 0.6118 accuracy: 0.9379: 100%|██████████| 298/298 [04:07<00:00,  1.21it/s]\n",
      "val_epoch: 35/300 Step: 299 loss : 1.0472 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.94it/s]\n",
      "epoch: 36/300 Step: 299 loss : 0.5983 accuracy: 0.9581: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 36/300 Step: 299 loss : 1.0485 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  7.28it/s]\n",
      "epoch: 37/300 Step: 299 loss : 0.5985 accuracy: 0.9555: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 37/300 Step: 299 loss : 1.0484 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.99it/s]\n",
      "epoch: 38/300 Step: 299 loss : 0.5945 accuracy: 0.9564: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 38/300 Step: 299 loss : 1.0451 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.69it/s]\n",
      "epoch: 39/300 Step: 299 loss : 0.5997 accuracy: 0.9555: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 39/300 Step: 299 loss : 1.0484 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.74it/s]\n",
      "epoch: 40/300 Step: 299 loss : 0.6114 accuracy: 0.9430: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 40/300 Step: 299 loss : 1.0387 accuracy: 0.5217: 100%|██████████| 46/46 [00:06<00:00,  7.07it/s]\n",
      "epoch: 41/300 Step: 299 loss : 0.6005 accuracy: 0.9530: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 41/300 Step: 299 loss : 1.0496 accuracy: 0.5163: 100%|██████████| 46/46 [00:07<00:00,  6.53it/s]\n",
      "epoch: 42/300 Step: 299 loss : 0.5894 accuracy: 0.9648: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 42/300 Step: 299 loss : 1.0481 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.59it/s]\n",
      "epoch: 43/300 Step: 299 loss : 0.5953 accuracy: 0.9555: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 43/300 Step: 299 loss : 1.0529 accuracy: 0.5109: 100%|██████████| 46/46 [00:06<00:00,  7.06it/s]\n",
      "epoch: 44/300 Step: 299 loss : 0.5924 accuracy: 0.9614: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 44/300 Step: 299 loss : 1.0794 accuracy: 0.4837: 100%|██████████| 46/46 [00:07<00:00,  6.56it/s]\n",
      "epoch: 45/300 Step: 299 loss : 0.5923 accuracy: 0.9606: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 45/300 Step: 299 loss : 1.0462 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  7.12it/s]\n",
      "epoch: 46/300 Step: 299 loss : 0.5873 accuracy: 0.9656: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 46/300 Step: 299 loss : 1.0608 accuracy: 0.5000: 100%|██████████| 46/46 [00:06<00:00,  6.58it/s]\n",
      "epoch: 47/300 Step: 299 loss : 0.5839 accuracy: 0.9698: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 47/300 Step: 299 loss : 1.0696 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  7.03it/s]\n",
      "epoch: 48/300 Step: 299 loss : 0.5810 accuracy: 0.9706: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 48/300 Step: 299 loss : 1.0772 accuracy: 0.4837: 100%|██████████| 46/46 [00:06<00:00,  6.87it/s]\n",
      "epoch: 49/300 Step: 299 loss : 0.5852 accuracy: 0.9664: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 49/300 Step: 299 loss : 1.0500 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  7.08it/s]\n",
      "epoch: 50/300 Step: 299 loss : 0.5817 accuracy: 0.9715: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 50/300 Step: 299 loss : 1.0678 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  7.02it/s]\n",
      "epoch: 51/300 Step: 299 loss : 0.5980 accuracy: 0.9564: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 51/300 Step: 299 loss : 1.0836 accuracy: 0.4783: 100%|██████████| 46/46 [00:06<00:00,  6.91it/s]\n",
      "epoch: 52/300 Step: 299 loss : 0.5786 accuracy: 0.9748: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 52/300 Step: 299 loss : 1.0469 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  7.06it/s]\n",
      "epoch: 53/300 Step: 299 loss : 0.5861 accuracy: 0.9673: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 53/300 Step: 299 loss : 1.0571 accuracy: 0.5054: 100%|██████████| 46/46 [00:07<00:00,  6.52it/s]\n",
      "epoch: 54/300 Step: 299 loss : 0.5782 accuracy: 0.9732: 100%|██████████| 298/298 [04:05<00:00,  1.22it/s]\n",
      "val_epoch: 54/300 Step: 299 loss : 1.0746 accuracy: 0.4891: 100%|██████████| 46/46 [00:06<00:00,  6.71it/s]\n",
      "epoch: 55/300 Step: 299 loss : 0.5828 accuracy: 0.9706: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 55/300 Step: 299 loss : 1.0906 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  6.87it/s]\n",
      "epoch: 56/300 Step: 299 loss : 0.5789 accuracy: 0.9732: 100%|██████████| 298/298 [04:07<00:00,  1.21it/s]\n",
      "val_epoch: 56/300 Step: 299 loss : 1.0690 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  6.84it/s]\n",
      "epoch: 57/300 Step: 299 loss : 0.5729 accuracy: 0.9799: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 57/300 Step: 299 loss : 1.0636 accuracy: 0.5000: 100%|██████████| 46/46 [00:06<00:00,  6.80it/s]\n",
      "epoch: 58/300 Step: 299 loss : 0.5724 accuracy: 0.9799: 100%|██████████| 298/298 [04:07<00:00,  1.21it/s]\n",
      "val_epoch: 58/300 Step: 299 loss : 1.0691 accuracy: 0.4891: 100%|██████████| 46/46 [00:06<00:00,  6.76it/s]\n",
      "epoch: 59/300 Step: 299 loss : 0.5770 accuracy: 0.9740: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 59/300 Step: 299 loss : 1.0889 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  6.76it/s]\n",
      "epoch: 60/300 Step: 299 loss : 0.5741 accuracy: 0.9790: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 60/300 Step: 299 loss : 1.0675 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  6.99it/s]\n",
      "epoch: 61/300 Step: 299 loss : 0.5719 accuracy: 0.9799: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 61/300 Step: 299 loss : 1.0661 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  7.10it/s]\n",
      "epoch: 62/300 Step: 299 loss : 0.5749 accuracy: 0.9790: 100%|██████████| 298/298 [04:05<00:00,  1.22it/s]\n",
      "val_epoch: 62/300 Step: 299 loss : 1.0572 accuracy: 0.5054: 100%|██████████| 46/46 [00:06<00:00,  6.61it/s]\n",
      "epoch: 63/300 Step: 299 loss : 0.5816 accuracy: 0.9715: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 63/300 Step: 299 loss : 1.0477 accuracy: 0.5163: 100%|██████████| 46/46 [00:07<00:00,  6.47it/s]\n",
      "epoch: 64/300 Step: 299 loss : 0.5704 accuracy: 0.9824: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 64/300 Step: 299 loss : 1.1127 accuracy: 0.4457: 100%|██████████| 46/46 [00:06<00:00,  7.01it/s]\n",
      "epoch: 65/300 Step: 299 loss : 0.5876 accuracy: 0.9631: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 65/300 Step: 299 loss : 1.1013 accuracy: 0.4565: 100%|██████████| 46/46 [00:06<00:00,  6.71it/s]\n",
      "epoch: 66/300 Step: 299 loss : 0.5736 accuracy: 0.9799: 100%|██████████| 298/298 [04:07<00:00,  1.20it/s]\n",
      "val_epoch: 66/300 Step: 299 loss : 1.0699 accuracy: 0.4891: 100%|██████████| 46/46 [00:06<00:00,  6.95it/s]\n",
      "epoch: 67/300 Step: 299 loss : 0.5768 accuracy: 0.9748: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 67/300 Step: 299 loss : 1.2507 accuracy: 0.2989: 100%|██████████| 46/46 [00:07<00:00,  6.54it/s]\n",
      "epoch: 68/300 Step: 299 loss : 0.5815 accuracy: 0.9706: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 68/300 Step: 299 loss : 1.2111 accuracy: 0.3424: 100%|██████████| 46/46 [00:06<00:00,  6.89it/s]\n",
      "epoch: 69/300 Step: 299 loss : 0.5754 accuracy: 0.9773: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 69/300 Step: 299 loss : 1.0346 accuracy: 0.5272: 100%|██████████| 46/46 [00:07<00:00,  6.56it/s]\n",
      "epoch: 70/300 Step: 299 loss : 0.5741 accuracy: 0.9790: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 70/300 Step: 299 loss : 1.0696 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  7.10it/s]\n",
      "epoch: 71/300 Step: 299 loss : 0.5716 accuracy: 0.9807: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 71/300 Step: 299 loss : 1.1633 accuracy: 0.3967: 100%|██████████| 46/46 [00:07<00:00,  6.45it/s]\n",
      "epoch: 72/300 Step: 299 loss : 0.5698 accuracy: 0.9832: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 72/300 Step: 299 loss : 1.0590 accuracy: 0.5054: 100%|██████████| 46/46 [00:06<00:00,  6.65it/s]\n",
      "epoch: 73/300 Step: 299 loss : 0.5693 accuracy: 0.9832: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 73/300 Step: 299 loss : 1.1227 accuracy: 0.4348: 100%|██████████| 46/46 [00:07<00:00,  6.48it/s]\n",
      "epoch: 74/300 Step: 299 loss : 0.5738 accuracy: 0.9773: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 74/300 Step: 299 loss : 1.3922 accuracy: 0.1467: 100%|██████████| 46/46 [00:07<00:00,  6.56it/s]\n",
      "epoch: 75/300 Step: 299 loss : 0.5721 accuracy: 0.9807: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 75/300 Step: 299 loss : 1.2747 accuracy: 0.2717: 100%|██████████| 46/46 [00:07<00:00,  6.52it/s]\n",
      "epoch: 76/300 Step: 299 loss : 0.5754 accuracy: 0.9765: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 76/300 Step: 299 loss : 1.1539 accuracy: 0.4076: 100%|██████████| 46/46 [00:06<00:00,  6.81it/s]\n",
      "epoch: 77/300 Step: 299 loss : 0.5771 accuracy: 0.9732: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 77/300 Step: 299 loss : 1.2275 accuracy: 0.3207: 100%|██████████| 46/46 [00:06<00:00,  6.64it/s]\n",
      "epoch: 78/300 Step: 299 loss : 0.5775 accuracy: 0.9740: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 78/300 Step: 299 loss : 1.1361 accuracy: 0.4185: 100%|██████████| 46/46 [00:06<00:00,  6.81it/s]\n",
      "epoch: 79/300 Step: 299 loss : 0.5708 accuracy: 0.9815: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 79/300 Step: 299 loss : 1.1745 accuracy: 0.3804: 100%|██████████| 46/46 [00:07<00:00,  6.40it/s]\n",
      "epoch: 80/300 Step: 299 loss : 0.5759 accuracy: 0.9757: 100%|██████████| 298/298 [04:07<00:00,  1.21it/s]\n",
      "val_epoch: 80/300 Step: 299 loss : 1.1195 accuracy: 0.4402: 100%|██████████| 46/46 [00:07<00:00,  6.48it/s]\n",
      "epoch: 81/300 Step: 299 loss : 0.5695 accuracy: 0.9832: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 81/300 Step: 299 loss : 1.0581 accuracy: 0.5054: 100%|██████████| 46/46 [00:06<00:00,  6.87it/s]\n",
      "epoch: 82/300 Step: 299 loss : 0.5697 accuracy: 0.9824: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 82/300 Step: 299 loss : 1.0511 accuracy: 0.5109: 100%|██████████| 46/46 [00:06<00:00,  7.12it/s]\n",
      "epoch: 83/300 Step: 299 loss : 0.5673 accuracy: 0.9841: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 83/300 Step: 299 loss : 1.0430 accuracy: 0.5217: 100%|██████████| 46/46 [00:07<00:00,  6.57it/s]\n",
      "epoch: 84/300 Step: 299 loss : 0.5694 accuracy: 0.9832: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 84/300 Step: 299 loss : 1.0684 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  6.59it/s]\n",
      "epoch: 85/300 Step: 299 loss : 0.5682 accuracy: 0.9841: 100%|██████████| 298/298 [04:09<00:00,  1.20it/s]\n",
      "val_epoch: 85/300 Step: 299 loss : 1.0425 accuracy: 0.5217: 100%|██████████| 46/46 [00:07<00:00,  6.39it/s]\n",
      "epoch: 86/300 Step: 299 loss : 0.5666 accuracy: 0.9849: 100%|██████████| 298/298 [04:08<00:00,  1.20it/s]\n",
      "val_epoch: 86/300 Step: 299 loss : 1.0488 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.60it/s]\n",
      "epoch: 87/300 Step: 299 loss : 0.5655 accuracy: 0.9866: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 87/300 Step: 299 loss : 1.0536 accuracy: 0.5109: 100%|██████████| 46/46 [00:07<00:00,  6.32it/s]\n",
      "epoch: 88/300 Step: 299 loss : 0.5668 accuracy: 0.9857: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 88/300 Step: 299 loss : 1.0641 accuracy: 0.5000: 100%|██████████| 46/46 [00:07<00:00,  6.40it/s]\n",
      "epoch: 89/300 Step: 299 loss : 0.5657 accuracy: 0.9857: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 89/300 Step: 299 loss : 1.0555 accuracy: 0.5109: 100%|██████████| 46/46 [00:06<00:00,  6.80it/s]\n",
      "epoch: 90/300 Step: 299 loss : 0.5777 accuracy: 0.9748: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 90/300 Step: 299 loss : 1.0496 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.60it/s]\n",
      "epoch: 91/300 Step: 299 loss : 0.5714 accuracy: 0.9824: 100%|██████████| 298/298 [04:05<00:00,  1.22it/s]\n",
      "val_epoch: 91/300 Step: 299 loss : 1.0465 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.64it/s]\n",
      "epoch: 92/300 Step: 299 loss : 0.5718 accuracy: 0.9790: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 92/300 Step: 299 loss : 1.0320 accuracy: 0.5326: 100%|██████████| 46/46 [00:06<00:00,  6.59it/s]\n",
      "epoch: 93/300 Step: 299 loss : 0.5671 accuracy: 0.9849: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 93/300 Step: 299 loss : 1.1062 accuracy: 0.4511: 100%|██████████| 46/46 [00:06<00:00,  7.07it/s]\n",
      "epoch: 94/300 Step: 299 loss : 0.5726 accuracy: 0.9790: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 94/300 Step: 299 loss : 1.0233 accuracy: 0.5380: 100%|██████████| 46/46 [00:07<00:00,  6.55it/s]\n",
      "epoch: 95/300 Step: 299 loss : 0.5701 accuracy: 0.9807: 100%|██████████| 298/298 [04:07<00:00,  1.20it/s]\n",
      "val_epoch: 95/300 Step: 299 loss : 1.0440 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.71it/s]\n",
      "epoch: 96/300 Step: 299 loss : 0.5761 accuracy: 0.9765: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 96/300 Step: 299 loss : 1.0417 accuracy: 0.5217: 100%|██████████| 46/46 [00:06<00:00,  7.11it/s]\n",
      "epoch: 97/300 Step: 299 loss : 0.5730 accuracy: 0.9790: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 97/300 Step: 299 loss : 1.0372 accuracy: 0.5272: 100%|██████████| 46/46 [00:07<00:00,  6.42it/s]\n",
      "epoch: 98/300 Step: 299 loss : 0.5680 accuracy: 0.9841: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 98/300 Step: 299 loss : 1.0464 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.76it/s]\n",
      "epoch: 99/300 Step: 299 loss : 0.5673 accuracy: 0.9849: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 99/300 Step: 299 loss : 1.0458 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.80it/s]\n",
      "epoch: 100/300 Step: 299 loss : 0.5680 accuracy: 0.9841: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 100/300 Step: 299 loss : 1.0489 accuracy: 0.5163: 100%|██████████| 46/46 [00:07<00:00,  6.51it/s]\n",
      "epoch: 101/300 Step: 299 loss : 0.5683 accuracy: 0.9832: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 101/300 Step: 299 loss : 1.0496 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  7.06it/s]\n",
      "epoch: 102/300 Step: 299 loss : 0.5675 accuracy: 0.9849: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 102/300 Step: 299 loss : 1.0534 accuracy: 0.5109: 100%|██████████| 46/46 [00:06<00:00,  6.88it/s]\n",
      "epoch: 103/300 Step: 299 loss : 0.5660 accuracy: 0.9857: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 103/300 Step: 299 loss : 1.0792 accuracy: 0.4837: 100%|██████████| 46/46 [00:07<00:00,  6.32it/s]\n",
      "epoch: 104/300 Step: 299 loss : 0.5653 accuracy: 0.9866: 100%|██████████| 298/298 [04:07<00:00,  1.20it/s]\n",
      "val_epoch: 104/300 Step: 299 loss : 1.0751 accuracy: 0.4891: 100%|██████████| 46/46 [00:06<00:00,  6.59it/s]\n",
      "epoch: 105/300 Step: 299 loss : 0.5653 accuracy: 0.9866: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 105/300 Step: 299 loss : 1.0426 accuracy: 0.5217: 100%|██████████| 46/46 [00:07<00:00,  6.57it/s]\n",
      "epoch: 106/300 Step: 299 loss : 0.5653 accuracy: 0.9866: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 106/300 Step: 299 loss : 1.0591 accuracy: 0.5054: 100%|██████████| 46/46 [00:06<00:00,  6.94it/s]\n",
      "epoch: 107/300 Step: 299 loss : 0.5671 accuracy: 0.9849: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 107/300 Step: 299 loss : 1.0572 accuracy: 0.5054: 100%|██████████| 46/46 [00:07<00:00,  6.49it/s]\n",
      "epoch: 108/300 Step: 299 loss : 0.5697 accuracy: 0.9824: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 108/300 Step: 299 loss : 1.0855 accuracy: 0.4783: 100%|██████████| 46/46 [00:07<00:00,  6.45it/s]\n",
      "epoch: 109/300 Step: 299 loss : 0.5708 accuracy: 0.9815: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 109/300 Step: 299 loss : 1.1196 accuracy: 0.4402: 100%|██████████| 46/46 [00:06<00:00,  6.85it/s]\n",
      "epoch: 110/300 Step: 299 loss : 0.5704 accuracy: 0.9815: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 110/300 Step: 299 loss : 1.1326 accuracy: 0.4239: 100%|██████████| 46/46 [00:06<00:00,  6.93it/s]\n",
      "epoch: 111/300 Step: 299 loss : 0.5851 accuracy: 0.9673: 100%|██████████| 298/298 [04:05<00:00,  1.22it/s]\n",
      "val_epoch: 111/300 Step: 299 loss : 1.0776 accuracy: 0.4837: 100%|██████████| 46/46 [00:06<00:00,  6.79it/s]\n",
      "epoch: 112/300 Step: 299 loss : 0.5730 accuracy: 0.9782: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 112/300 Step: 299 loss : 1.0933 accuracy: 0.4674: 100%|██████████| 46/46 [00:06<00:00,  6.60it/s]\n",
      "epoch: 113/300 Step: 299 loss : 0.5668 accuracy: 0.9849: 100%|██████████| 298/298 [04:06<00:00,  1.21it/s]\n",
      "val_epoch: 113/300 Step: 299 loss : 1.0304 accuracy: 0.5326: 100%|██████████| 46/46 [00:06<00:00,  7.00it/s]\n",
      "epoch: 114/300 Step: 299 loss : 0.5670 accuracy: 0.9857: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 114/300 Step: 299 loss : 1.0835 accuracy: 0.4783: 100%|██████████| 46/46 [00:06<00:00,  6.96it/s]\n",
      "epoch: 115/300 Step: 299 loss : 0.5645 accuracy: 0.9866: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 115/300 Step: 299 loss : 1.1168 accuracy: 0.4457: 100%|██████████| 46/46 [00:06<00:00,  7.27it/s]\n",
      "epoch: 116/300 Step: 299 loss : 0.5656 accuracy: 0.9866: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 116/300 Step: 299 loss : 1.0944 accuracy: 0.4674: 100%|██████████| 46/46 [00:06<00:00,  6.92it/s]\n",
      "epoch: 117/300 Step: 299 loss : 0.5643 accuracy: 0.9883: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 117/300 Step: 299 loss : 1.1010 accuracy: 0.4620: 100%|██████████| 46/46 [00:06<00:00,  6.88it/s]\n",
      "epoch: 118/300 Step: 299 loss : 0.5648 accuracy: 0.9874: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 118/300 Step: 299 loss : 1.0848 accuracy: 0.4783: 100%|██████████| 46/46 [00:06<00:00,  6.78it/s]\n",
      "epoch: 119/300 Step: 299 loss : 0.5662 accuracy: 0.9849: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 119/300 Step: 299 loss : 1.0477 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  7.14it/s]\n",
      "epoch: 120/300 Step: 299 loss : 0.5656 accuracy: 0.9866: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 120/300 Step: 299 loss : 1.0833 accuracy: 0.4783: 100%|██████████| 46/46 [00:06<00:00,  7.00it/s]\n",
      "epoch: 121/300 Step: 299 loss : 0.5649 accuracy: 0.9883: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 121/300 Step: 299 loss : 1.1098 accuracy: 0.4511: 100%|██████████| 46/46 [00:06<00:00,  7.06it/s]\n",
      "epoch: 122/300 Step: 299 loss : 0.5692 accuracy: 0.9841: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 122/300 Step: 299 loss : 1.1737 accuracy: 0.3859: 100%|██████████| 46/46 [00:06<00:00,  7.36it/s]\n",
      "epoch: 123/300 Step: 299 loss : 0.5655 accuracy: 0.9866: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 123/300 Step: 299 loss : 1.0896 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  6.85it/s]\n",
      "epoch: 124/300 Step: 299 loss : 0.5654 accuracy: 0.9866: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 124/300 Step: 299 loss : 1.1005 accuracy: 0.4620: 100%|██████████| 46/46 [00:06<00:00,  6.96it/s]\n",
      "epoch: 125/300 Step: 299 loss : 0.5644 accuracy: 0.9874: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 125/300 Step: 299 loss : 1.1176 accuracy: 0.4457: 100%|██████████| 46/46 [00:06<00:00,  6.68it/s]\n",
      "epoch: 126/300 Step: 299 loss : 0.5642 accuracy: 0.9883: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 126/300 Step: 299 loss : 1.0818 accuracy: 0.4783: 100%|██████████| 46/46 [00:06<00:00,  6.94it/s]\n",
      "epoch: 127/300 Step: 299 loss : 0.5638 accuracy: 0.9883: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 127/300 Step: 299 loss : 1.0817 accuracy: 0.4783: 100%|██████████| 46/46 [00:06<00:00,  6.94it/s]\n",
      "epoch: 128/300 Step: 299 loss : 0.5638 accuracy: 0.9883: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 128/300 Step: 299 loss : 1.0664 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  6.98it/s]\n",
      "epoch: 129/300 Step: 299 loss : 0.5634 accuracy: 0.9883: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 129/300 Step: 299 loss : 1.0815 accuracy: 0.4783: 100%|██████████| 46/46 [00:06<00:00,  6.94it/s]\n",
      "epoch: 130/300 Step: 299 loss : 0.5637 accuracy: 0.9883: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 130/300 Step: 299 loss : 1.1061 accuracy: 0.4565: 100%|██████████| 46/46 [00:06<00:00,  7.17it/s]\n",
      "epoch: 131/300 Step: 299 loss : 0.5630 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 131/300 Step: 299 loss : 1.1682 accuracy: 0.3913: 100%|██████████| 46/46 [00:06<00:00,  7.09it/s]\n",
      "epoch: 132/300 Step: 299 loss : 0.5634 accuracy: 0.9883: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 132/300 Step: 299 loss : 1.2354 accuracy: 0.3207: 100%|██████████| 46/46 [00:06<00:00,  6.93it/s]\n",
      "epoch: 133/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 133/300 Step: 299 loss : 1.1289 accuracy: 0.4293: 100%|██████████| 46/46 [00:06<00:00,  6.74it/s]\n",
      "epoch: 134/300 Step: 299 loss : 0.5629 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 134/300 Step: 299 loss : 1.0543 accuracy: 0.5054: 100%|██████████| 46/46 [00:06<00:00,  7.12it/s]\n",
      "epoch: 135/300 Step: 299 loss : 0.5633 accuracy: 0.9883: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 135/300 Step: 299 loss : 1.1075 accuracy: 0.4511: 100%|██████████| 46/46 [00:06<00:00,  7.10it/s]\n",
      "epoch: 136/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 136/300 Step: 299 loss : 1.0862 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  7.01it/s]\n",
      "epoch: 137/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 137/300 Step: 299 loss : 1.0646 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  7.04it/s]\n",
      "epoch: 138/300 Step: 299 loss : 0.5631 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 138/300 Step: 299 loss : 1.0738 accuracy: 0.4837: 100%|██████████| 46/46 [00:06<00:00,  7.11it/s]\n",
      "epoch: 139/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 139/300 Step: 299 loss : 1.1305 accuracy: 0.4293: 100%|██████████| 46/46 [00:06<00:00,  7.27it/s]\n",
      "epoch: 140/300 Step: 299 loss : 0.5629 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 140/300 Step: 299 loss : 1.1253 accuracy: 0.4348: 100%|██████████| 46/46 [00:06<00:00,  6.95it/s]\n",
      "epoch: 141/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 141/300 Step: 299 loss : 1.1098 accuracy: 0.4511: 100%|██████████| 46/46 [00:06<00:00,  7.00it/s]\n",
      "epoch: 142/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 142/300 Step: 299 loss : 1.1478 accuracy: 0.4076: 100%|██████████| 46/46 [00:06<00:00,  6.81it/s]\n",
      "epoch: 143/300 Step: 299 loss : 0.5629 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 143/300 Step: 299 loss : 1.1126 accuracy: 0.4457: 100%|██████████| 46/46 [00:06<00:00,  7.01it/s]\n",
      "epoch: 144/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 144/300 Step: 299 loss : 1.1949 accuracy: 0.3641: 100%|██████████| 46/46 [00:06<00:00,  7.06it/s]\n",
      "epoch: 145/300 Step: 299 loss : 0.5635 accuracy: 0.9883: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 145/300 Step: 299 loss : 1.0621 accuracy: 0.5000: 100%|██████████| 46/46 [00:06<00:00,  6.99it/s]\n",
      "epoch: 146/300 Step: 299 loss : 0.5637 accuracy: 0.9883: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 146/300 Step: 299 loss : 1.0661 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  7.05it/s]\n",
      "epoch: 147/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 147/300 Step: 299 loss : 1.0767 accuracy: 0.4837: 100%|██████████| 46/46 [00:06<00:00,  7.21it/s]\n",
      "epoch: 148/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 148/300 Step: 299 loss : 1.0888 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  7.16it/s]\n",
      "epoch: 149/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 149/300 Step: 299 loss : 1.0668 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  7.18it/s]\n",
      "epoch: 150/300 Step: 299 loss : 0.5630 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 150/300 Step: 299 loss : 1.0887 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  6.95it/s]\n",
      "epoch: 151/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 151/300 Step: 299 loss : 1.0614 accuracy: 0.5000: 100%|██████████| 46/46 [00:06<00:00,  7.48it/s]\n",
      "epoch: 152/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 152/300 Step: 299 loss : 1.0660 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  7.02it/s]\n",
      "epoch: 153/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 153/300 Step: 299 loss : 1.0862 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  6.91it/s]\n",
      "epoch: 154/300 Step: 299 loss : 0.5629 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 154/300 Step: 299 loss : 1.0573 accuracy: 0.5000: 100%|██████████| 46/46 [00:06<00:00,  7.03it/s]\n",
      "epoch: 155/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 155/300 Step: 299 loss : 1.0659 accuracy: 0.4946: 100%|██████████| 46/46 [00:05<00:00,  7.72it/s]\n",
      "epoch: 156/300 Step: 299 loss : 0.5630 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 156/300 Step: 299 loss : 1.0543 accuracy: 0.5054: 100%|██████████| 46/46 [00:06<00:00,  7.64it/s]\n",
      "epoch: 157/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 157/300 Step: 299 loss : 1.1091 accuracy: 0.4511: 100%|██████████| 46/46 [00:05<00:00,  7.83it/s]\n",
      "epoch: 158/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 158/300 Step: 299 loss : 1.0569 accuracy: 0.5054: 100%|██████████| 46/46 [00:06<00:00,  6.85it/s]\n",
      "epoch: 159/300 Step: 299 loss : 0.5629 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 159/300 Step: 299 loss : 1.1056 accuracy: 0.4511: 100%|██████████| 46/46 [00:07<00:00,  6.55it/s]\n",
      "epoch: 160/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 160/300 Step: 299 loss : 1.0832 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  6.95it/s]\n",
      "epoch: 161/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 161/300 Step: 299 loss : 1.1088 accuracy: 0.4511: 100%|██████████| 46/46 [00:06<00:00,  7.19it/s]\n",
      "epoch: 162/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 162/300 Step: 299 loss : 1.0827 accuracy: 0.4783: 100%|██████████| 46/46 [00:06<00:00,  7.29it/s]\n",
      "epoch: 163/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 163/300 Step: 299 loss : 1.0986 accuracy: 0.4620: 100%|██████████| 46/46 [00:06<00:00,  7.01it/s]\n",
      "epoch: 164/300 Step: 299 loss : 0.5621 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 164/300 Step: 299 loss : 1.1045 accuracy: 0.4565: 100%|██████████| 46/46 [00:06<00:00,  7.12it/s]\n",
      "epoch: 165/300 Step: 299 loss : 0.5629 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 165/300 Step: 299 loss : 1.0962 accuracy: 0.4620: 100%|██████████| 46/46 [00:06<00:00,  7.00it/s]\n",
      "epoch: 166/300 Step: 299 loss : 0.5629 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 166/300 Step: 299 loss : 1.0928 accuracy: 0.4674: 100%|██████████| 46/46 [00:06<00:00,  7.43it/s]\n",
      "epoch: 167/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 167/300 Step: 299 loss : 1.0430 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  7.66it/s]\n",
      "epoch: 168/300 Step: 299 loss : 0.5625 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 168/300 Step: 299 loss : 1.0527 accuracy: 0.5109: 100%|██████████| 46/46 [00:06<00:00,  6.95it/s]\n",
      "epoch: 169/300 Step: 299 loss : 0.5625 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 169/300 Step: 299 loss : 1.1018 accuracy: 0.4565: 100%|██████████| 46/46 [00:06<00:00,  7.19it/s]\n",
      "epoch: 170/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 170/300 Step: 299 loss : 1.0490 accuracy: 0.5109: 100%|██████████| 46/46 [00:06<00:00,  7.10it/s]\n",
      "epoch: 171/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 171/300 Step: 299 loss : 1.0961 accuracy: 0.4674: 100%|██████████| 46/46 [00:06<00:00,  7.08it/s]\n",
      "epoch: 172/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 172/300 Step: 299 loss : 1.0629 accuracy: 0.5000: 100%|██████████| 46/46 [00:06<00:00,  6.94it/s]\n",
      "epoch: 173/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 173/300 Step: 299 loss : 1.1164 accuracy: 0.4402: 100%|██████████| 46/46 [00:06<00:00,  7.29it/s]\n",
      "epoch: 174/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 174/300 Step: 299 loss : 1.0668 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  6.86it/s]\n",
      "epoch: 175/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 175/300 Step: 299 loss : 1.0281 accuracy: 0.5326: 100%|██████████| 46/46 [00:06<00:00,  7.17it/s]\n",
      "epoch: 176/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 176/300 Step: 299 loss : 1.1308 accuracy: 0.4293: 100%|██████████| 46/46 [00:06<00:00,  7.02it/s]\n",
      "epoch: 177/300 Step: 299 loss : 0.5629 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 177/300 Step: 299 loss : 1.0511 accuracy: 0.5109: 100%|██████████| 46/46 [00:06<00:00,  6.93it/s]\n",
      "epoch: 178/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 178/300 Step: 299 loss : 1.1148 accuracy: 0.4457: 100%|██████████| 46/46 [00:06<00:00,  7.11it/s]\n",
      "epoch: 179/300 Step: 299 loss : 0.5625 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 179/300 Step: 299 loss : 1.1155 accuracy: 0.4457: 100%|██████████| 46/46 [00:06<00:00,  7.27it/s]\n",
      "epoch: 180/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 180/300 Step: 299 loss : 1.1180 accuracy: 0.4402: 100%|██████████| 46/46 [00:05<00:00,  7.76it/s]\n",
      "epoch: 181/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 181/300 Step: 299 loss : 1.1010 accuracy: 0.4620: 100%|██████████| 46/46 [00:06<00:00,  7.52it/s]\n",
      "epoch: 182/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:01<00:00,  1.23it/s]\n",
      "val_epoch: 182/300 Step: 299 loss : 1.1159 accuracy: 0.4457: 100%|██████████| 46/46 [00:06<00:00,  7.37it/s]\n",
      "epoch: 183/300 Step: 299 loss : 0.5636 accuracy: 0.9883: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 183/300 Step: 299 loss : 1.1213 accuracy: 0.4402: 100%|██████████| 46/46 [00:06<00:00,  6.91it/s]\n",
      "epoch: 184/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 184/300 Step: 299 loss : 1.0169 accuracy: 0.5435: 100%|██████████| 46/46 [00:06<00:00,  6.93it/s]\n",
      "epoch: 185/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 185/300 Step: 299 loss : 1.0946 accuracy: 0.4674: 100%|██████████| 46/46 [00:06<00:00,  6.96it/s]\n",
      "epoch: 186/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 186/300 Step: 299 loss : 1.0415 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.89it/s]\n",
      "epoch: 187/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 187/300 Step: 299 loss : 1.0838 accuracy: 0.4783: 100%|██████████| 46/46 [00:06<00:00,  7.09it/s]\n",
      "epoch: 188/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 188/300 Step: 299 loss : 1.0504 accuracy: 0.5109: 100%|██████████| 46/46 [00:06<00:00,  6.67it/s]\n",
      "epoch: 189/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 189/300 Step: 299 loss : 1.0717 accuracy: 0.4891: 100%|██████████| 46/46 [00:06<00:00,  6.98it/s]\n",
      "epoch: 190/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 190/300 Step: 299 loss : 1.0876 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  6.88it/s]\n",
      "epoch: 191/300 Step: 299 loss : 0.5624 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 191/300 Step: 299 loss : 1.1030 accuracy: 0.4565: 100%|██████████| 46/46 [00:06<00:00,  7.15it/s]\n",
      "epoch: 192/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 192/300 Step: 299 loss : 1.1029 accuracy: 0.4565: 100%|██████████| 46/46 [00:06<00:00,  7.21it/s]\n",
      "epoch: 193/300 Step: 299 loss : 0.5622 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 193/300 Step: 299 loss : 1.0775 accuracy: 0.4837: 100%|██████████| 46/46 [00:06<00:00,  7.04it/s]\n",
      "epoch: 194/300 Step: 299 loss : 0.5629 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 194/300 Step: 299 loss : 1.0503 accuracy: 0.5109: 100%|██████████| 46/46 [00:06<00:00,  7.05it/s]\n",
      "epoch: 195/300 Step: 299 loss : 0.5629 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 195/300 Step: 299 loss : 1.1652 accuracy: 0.3913: 100%|██████████| 46/46 [00:06<00:00,  7.32it/s]\n",
      "epoch: 196/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 196/300 Step: 299 loss : 1.1095 accuracy: 0.4511: 100%|██████████| 46/46 [00:06<00:00,  6.84it/s]\n",
      "epoch: 197/300 Step: 299 loss : 0.5625 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 197/300 Step: 299 loss : 1.0452 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  6.60it/s]\n",
      "epoch: 198/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 198/300 Step: 299 loss : 1.1100 accuracy: 0.4511: 100%|██████████| 46/46 [00:07<00:00,  6.55it/s]\n",
      "epoch: 199/300 Step: 299 loss : 0.5622 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 199/300 Step: 299 loss : 1.1238 accuracy: 0.4348: 100%|██████████| 46/46 [00:06<00:00,  7.48it/s]\n",
      "epoch: 200/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 200/300 Step: 299 loss : 1.1295 accuracy: 0.4293: 100%|██████████| 46/46 [00:06<00:00,  6.87it/s]\n",
      "epoch: 201/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 201/300 Step: 299 loss : 1.1478 accuracy: 0.4130: 100%|██████████| 46/46 [00:06<00:00,  6.92it/s]\n",
      "epoch: 202/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 202/300 Step: 299 loss : 1.1709 accuracy: 0.3859: 100%|██████████| 46/46 [00:06<00:00,  6.88it/s]\n",
      "epoch: 203/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 203/300 Step: 299 loss : 1.0809 accuracy: 0.4783: 100%|██████████| 46/46 [00:06<00:00,  7.03it/s]\n",
      "epoch: 204/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 204/300 Step: 299 loss : 1.1672 accuracy: 0.3913: 100%|██████████| 46/46 [00:06<00:00,  6.85it/s]\n",
      "epoch: 205/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 205/300 Step: 299 loss : 1.0971 accuracy: 0.4620: 100%|██████████| 46/46 [00:06<00:00,  7.07it/s]\n",
      "epoch: 206/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 206/300 Step: 299 loss : 1.0968 accuracy: 0.4620: 100%|██████████| 46/46 [00:06<00:00,  7.53it/s]\n",
      "epoch: 207/300 Step: 299 loss : 0.5629 accuracy: 0.9891: 100%|██████████| 298/298 [04:05<00:00,  1.22it/s]\n",
      "val_epoch: 207/300 Step: 299 loss : 1.1472 accuracy: 0.4130: 100%|██████████| 46/46 [00:06<00:00,  6.58it/s]\n",
      "epoch: 208/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 208/300 Step: 299 loss : 1.0991 accuracy: 0.4620: 100%|██████████| 46/46 [00:06<00:00,  7.41it/s]\n",
      "epoch: 209/300 Step: 299 loss : 0.5629 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 209/300 Step: 299 loss : 1.1396 accuracy: 0.4185: 100%|██████████| 46/46 [00:06<00:00,  6.99it/s]\n",
      "epoch: 210/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 210/300 Step: 299 loss : 1.1513 accuracy: 0.4076: 100%|██████████| 46/46 [00:06<00:00,  7.05it/s]\n",
      "epoch: 211/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 211/300 Step: 299 loss : 1.1676 accuracy: 0.3913: 100%|██████████| 46/46 [00:06<00:00,  6.80it/s]\n",
      "epoch: 212/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 212/300 Step: 299 loss : 1.1819 accuracy: 0.3750: 100%|██████████| 46/46 [00:06<00:00,  7.12it/s]\n",
      "epoch: 213/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 213/300 Step: 299 loss : 1.1778 accuracy: 0.3804: 100%|██████████| 46/46 [00:06<00:00,  7.16it/s]\n",
      "epoch: 214/300 Step: 299 loss : 0.5630 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 214/300 Step: 299 loss : 1.0985 accuracy: 0.4620: 100%|██████████| 46/46 [00:06<00:00,  7.35it/s]\n",
      "epoch: 215/300 Step: 299 loss : 0.5624 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 215/300 Step: 299 loss : 1.1262 accuracy: 0.4348: 100%|██████████| 46/46 [00:06<00:00,  7.13it/s]\n",
      "epoch: 216/300 Step: 299 loss : 0.5628 accuracy: 0.9891: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 216/300 Step: 299 loss : 1.1508 accuracy: 0.4076: 100%|██████████| 46/46 [00:06<00:00,  7.21it/s]\n",
      "epoch: 217/300 Step: 299 loss : 0.5626 accuracy: 0.9891: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 217/300 Step: 299 loss : 1.1342 accuracy: 0.4239: 100%|██████████| 46/46 [00:06<00:00,  7.04it/s]\n",
      "epoch: 218/300 Step: 299 loss : 0.5627 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 218/300 Step: 299 loss : 1.1335 accuracy: 0.4239: 100%|██████████| 46/46 [00:06<00:00,  7.21it/s]\n",
      "epoch: 219/300 Step: 299 loss : 0.5625 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 219/300 Step: 299 loss : 1.1464 accuracy: 0.4130: 100%|██████████| 46/46 [00:06<00:00,  7.29it/s]\n",
      "epoch: 220/300 Step: 299 loss : 0.5624 accuracy: 0.9891: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 220/300 Step: 299 loss : 1.0894 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  7.18it/s]\n",
      "epoch: 221/300 Step: 299 loss : 0.5620 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 221/300 Step: 299 loss : 1.0866 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  7.17it/s]\n",
      "epoch: 222/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 222/300 Step: 299 loss : 1.1033 accuracy: 0.4565: 100%|██████████| 46/46 [00:06<00:00,  7.15it/s]\n",
      "epoch: 223/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 223/300 Step: 299 loss : 1.1256 accuracy: 0.4348: 100%|██████████| 46/46 [00:06<00:00,  7.55it/s]\n",
      "epoch: 224/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 224/300 Step: 299 loss : 1.0988 accuracy: 0.4620: 100%|██████████| 46/46 [00:06<00:00,  7.02it/s]\n",
      "epoch: 225/300 Step: 299 loss : 0.5616 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 225/300 Step: 299 loss : 1.1247 accuracy: 0.4348: 100%|██████████| 46/46 [00:06<00:00,  7.27it/s]\n",
      "epoch: 226/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 226/300 Step: 299 loss : 1.0126 accuracy: 0.5489: 100%|██████████| 46/46 [00:06<00:00,  6.91it/s]\n",
      "epoch: 227/300 Step: 299 loss : 0.5620 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 227/300 Step: 299 loss : 1.0144 accuracy: 0.5489: 100%|██████████| 46/46 [00:06<00:00,  7.27it/s]\n",
      "epoch: 228/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 228/300 Step: 299 loss : 1.0556 accuracy: 0.5054: 100%|██████████| 46/46 [00:06<00:00,  7.03it/s]\n",
      "epoch: 229/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 229/300 Step: 299 loss : 1.0063 accuracy: 0.5543: 100%|██████████| 46/46 [00:06<00:00,  6.98it/s]\n",
      "epoch: 230/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 230/300 Step: 299 loss : 1.0827 accuracy: 0.4783: 100%|██████████| 46/46 [00:06<00:00,  6.67it/s]\n",
      "epoch: 231/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 231/300 Step: 299 loss : 1.1252 accuracy: 0.4348: 100%|██████████| 46/46 [00:06<00:00,  7.10it/s]\n",
      "epoch: 232/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 232/300 Step: 299 loss : 1.1148 accuracy: 0.4457: 100%|██████████| 46/46 [00:06<00:00,  6.95it/s]\n",
      "epoch: 233/300 Step: 299 loss : 0.5620 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 233/300 Step: 299 loss : 1.0991 accuracy: 0.4620: 100%|██████████| 46/46 [00:06<00:00,  7.08it/s]\n",
      "epoch: 234/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 234/300 Step: 299 loss : 1.1126 accuracy: 0.4457: 100%|██████████| 46/46 [00:06<00:00,  7.19it/s]\n",
      "epoch: 235/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 235/300 Step: 299 loss : 1.0850 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  6.89it/s]\n",
      "epoch: 236/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 236/300 Step: 299 loss : 1.0933 accuracy: 0.4674: 100%|██████████| 46/46 [00:06<00:00,  7.40it/s]\n",
      "epoch: 237/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 237/300 Step: 299 loss : 1.0062 accuracy: 0.5543: 100%|██████████| 46/46 [00:05<00:00,  7.74it/s]\n",
      "epoch: 238/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 238/300 Step: 299 loss : 1.0767 accuracy: 0.4837: 100%|██████████| 46/46 [00:05<00:00,  7.78it/s]\n",
      "epoch: 239/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 239/300 Step: 299 loss : 1.0665 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  6.86it/s]\n",
      "epoch: 240/300 Step: 299 loss : 0.5616 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 240/300 Step: 299 loss : 1.1017 accuracy: 0.4565: 100%|██████████| 46/46 [00:06<00:00,  6.94it/s]\n",
      "epoch: 241/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 241/300 Step: 299 loss : 1.0749 accuracy: 0.4837: 100%|██████████| 46/46 [00:06<00:00,  7.13it/s]\n",
      "epoch: 242/300 Step: 299 loss : 0.5615 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 242/300 Step: 299 loss : 1.0609 accuracy: 0.5000: 100%|██████████| 46/46 [00:06<00:00,  7.38it/s]\n",
      "epoch: 243/300 Step: 299 loss : 0.5616 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 243/300 Step: 299 loss : 1.0755 accuracy: 0.4837: 100%|██████████| 46/46 [00:06<00:00,  7.20it/s]\n",
      "epoch: 244/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 244/300 Step: 299 loss : 1.0731 accuracy: 0.4837: 100%|██████████| 46/46 [00:06<00:00,  7.04it/s]\n",
      "epoch: 245/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 245/300 Step: 299 loss : 1.0288 accuracy: 0.5326: 100%|██████████| 46/46 [00:06<00:00,  7.10it/s]\n",
      "epoch: 246/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 246/300 Step: 299 loss : 1.0882 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  7.03it/s]\n",
      "epoch: 247/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 247/300 Step: 299 loss : 1.0973 accuracy: 0.4620: 100%|██████████| 46/46 [00:06<00:00,  6.96it/s]\n",
      "epoch: 248/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 248/300 Step: 299 loss : 1.1378 accuracy: 0.4239: 100%|██████████| 46/46 [00:06<00:00,  7.53it/s]\n",
      "epoch: 249/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 249/300 Step: 299 loss : 1.0433 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  7.04it/s]\n",
      "epoch: 250/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 250/300 Step: 299 loss : 1.0645 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  6.94it/s]\n",
      "epoch: 251/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 251/300 Step: 299 loss : 1.0533 accuracy: 0.5054: 100%|██████████| 46/46 [00:06<00:00,  6.77it/s]\n",
      "epoch: 252/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 252/300 Step: 299 loss : 1.0447 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  7.02it/s]\n",
      "epoch: 253/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 253/300 Step: 299 loss : 1.0615 accuracy: 0.5000: 100%|██████████| 46/46 [00:06<00:00,  7.03it/s]\n",
      "epoch: 254/300 Step: 299 loss : 0.5615 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 254/300 Step: 299 loss : 1.1151 accuracy: 0.4457: 100%|██████████| 46/46 [00:06<00:00,  6.95it/s]\n",
      "epoch: 255/300 Step: 299 loss : 0.5621 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 255/300 Step: 299 loss : 1.0639 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  7.11it/s]\n",
      "epoch: 256/300 Step: 299 loss : 0.5616 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 256/300 Step: 299 loss : 1.0711 accuracy: 0.4891: 100%|██████████| 46/46 [00:06<00:00,  7.05it/s]\n",
      "epoch: 257/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 257/300 Step: 299 loss : 1.0486 accuracy: 0.5109: 100%|██████████| 46/46 [00:06<00:00,  7.16it/s]\n",
      "epoch: 258/300 Step: 299 loss : 0.5616 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 258/300 Step: 299 loss : 1.0464 accuracy: 0.5109: 100%|██████████| 46/46 [00:06<00:00,  7.27it/s]\n",
      "epoch: 259/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 259/300 Step: 299 loss : 1.0721 accuracy: 0.4891: 100%|██████████| 46/46 [00:06<00:00,  7.48it/s]\n",
      "epoch: 260/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 260/300 Step: 299 loss : 1.0204 accuracy: 0.5435: 100%|██████████| 46/46 [00:06<00:00,  6.98it/s]\n",
      "epoch: 261/300 Step: 299 loss : 0.5620 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 261/300 Step: 299 loss : 1.0853 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  7.13it/s]\n",
      "epoch: 262/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 262/300 Step: 299 loss : 1.0233 accuracy: 0.5380: 100%|██████████| 46/46 [00:06<00:00,  6.97it/s]\n",
      "epoch: 263/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 263/300 Step: 299 loss : 1.1146 accuracy: 0.4457: 100%|██████████| 46/46 [00:06<00:00,  6.81it/s]\n",
      "epoch: 264/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 264/300 Step: 299 loss : 1.0131 accuracy: 0.5489: 100%|██████████| 46/46 [00:06<00:00,  7.12it/s]\n",
      "epoch: 265/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 265/300 Step: 299 loss : 1.0658 accuracy: 0.4946: 100%|██████████| 46/46 [00:06<00:00,  6.95it/s]\n",
      "epoch: 266/300 Step: 299 loss : 0.5620 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 266/300 Step: 299 loss : 1.0294 accuracy: 0.5326: 100%|██████████| 46/46 [00:06<00:00,  7.12it/s]\n",
      "epoch: 267/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 267/300 Step: 299 loss : 0.9932 accuracy: 0.5652: 100%|██████████| 46/46 [00:06<00:00,  7.02it/s]\n",
      "epoch: 268/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 268/300 Step: 299 loss : 1.0466 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  7.29it/s]\n",
      "epoch: 269/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 269/300 Step: 299 loss : 1.0462 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  7.22it/s]\n",
      "epoch: 270/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 270/300 Step: 299 loss : 1.0322 accuracy: 0.5272: 100%|██████████| 46/46 [00:06<00:00,  7.15it/s]\n",
      "epoch: 271/300 Step: 299 loss : 0.5616 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 271/300 Step: 299 loss : 1.0382 accuracy: 0.5217: 100%|██████████| 46/46 [00:06<00:00,  7.11it/s]\n",
      "epoch: 272/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 272/300 Step: 299 loss : 1.0280 accuracy: 0.5326: 100%|██████████| 46/46 [00:06<00:00,  7.07it/s]\n",
      "epoch: 273/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 273/300 Step: 299 loss : 1.0225 accuracy: 0.5380: 100%|██████████| 46/46 [00:06<00:00,  7.66it/s]\n",
      "epoch: 274/300 Step: 299 loss : 0.5615 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 274/300 Step: 299 loss : 1.0390 accuracy: 0.5217: 100%|██████████| 46/46 [00:06<00:00,  7.19it/s]\n",
      "epoch: 275/300 Step: 299 loss : 0.5620 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 275/300 Step: 299 loss : 0.9773 accuracy: 0.5870: 100%|██████████| 46/46 [00:06<00:00,  7.16it/s]\n",
      "epoch: 276/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 276/300 Step: 299 loss : 1.0126 accuracy: 0.5489: 100%|██████████| 46/46 [00:06<00:00,  7.36it/s]\n",
      "epoch: 277/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 277/300 Step: 299 loss : 0.9910 accuracy: 0.5707: 100%|██████████| 46/46 [00:05<00:00,  7.77it/s]\n",
      "epoch: 278/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 278/300 Step: 299 loss : 1.0609 accuracy: 0.5000: 100%|██████████| 46/46 [00:07<00:00,  6.55it/s]\n",
      "epoch: 279/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:05<00:00,  1.21it/s]\n",
      "val_epoch: 279/300 Step: 299 loss : 1.0439 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  7.02it/s]\n",
      "epoch: 280/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 280/300 Step: 299 loss : 1.0872 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  6.93it/s]\n",
      "epoch: 281/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 281/300 Step: 299 loss : 1.0574 accuracy: 0.5054: 100%|██████████| 46/46 [00:06<00:00,  7.05it/s]\n",
      "epoch: 282/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 282/300 Step: 299 loss : 0.9849 accuracy: 0.5761: 100%|██████████| 46/46 [00:06<00:00,  7.04it/s]\n",
      "epoch: 283/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 283/300 Step: 299 loss : 1.0828 accuracy: 0.4783: 100%|██████████| 46/46 [00:06<00:00,  7.28it/s]\n",
      "epoch: 284/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 284/300 Step: 299 loss : 1.0821 accuracy: 0.4783: 100%|██████████| 46/46 [00:06<00:00,  7.00it/s]\n",
      "epoch: 285/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 285/300 Step: 299 loss : 1.0828 accuracy: 0.4783: 100%|██████████| 46/46 [00:06<00:00,  6.93it/s]\n",
      "epoch: 286/300 Step: 299 loss : 0.5614 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 286/300 Step: 299 loss : 1.0285 accuracy: 0.5326: 100%|██████████| 46/46 [00:06<00:00,  7.06it/s]\n",
      "epoch: 287/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 287/300 Step: 299 loss : 1.0498 accuracy: 0.5109: 100%|██████████| 46/46 [00:06<00:00,  6.98it/s]\n",
      "epoch: 288/300 Step: 299 loss : 0.5620 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 288/300 Step: 299 loss : 1.0267 accuracy: 0.5326: 100%|██████████| 46/46 [00:06<00:00,  7.23it/s]\n",
      "epoch: 289/300 Step: 299 loss : 0.5616 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 289/300 Step: 299 loss : 0.9903 accuracy: 0.5707: 100%|██████████| 46/46 [00:06<00:00,  6.94it/s]\n",
      "epoch: 290/300 Step: 299 loss : 0.5620 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 290/300 Step: 299 loss : 1.0382 accuracy: 0.5217: 100%|██████████| 46/46 [00:06<00:00,  7.13it/s]\n",
      "epoch: 291/300 Step: 299 loss : 0.5615 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 291/300 Step: 299 loss : 1.0131 accuracy: 0.5489: 100%|██████████| 46/46 [00:06<00:00,  7.42it/s]\n",
      "epoch: 292/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 292/300 Step: 299 loss : 1.0022 accuracy: 0.5598: 100%|██████████| 46/46 [00:06<00:00,  7.55it/s]\n",
      "epoch: 293/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.23it/s]\n",
      "val_epoch: 293/300 Step: 299 loss : 1.0465 accuracy: 0.5163: 100%|██████████| 46/46 [00:06<00:00,  7.21it/s]\n",
      "epoch: 294/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 294/300 Step: 299 loss : 1.0487 accuracy: 0.5109: 100%|██████████| 46/46 [00:06<00:00,  6.99it/s]\n",
      "epoch: 295/300 Step: 299 loss : 0.5615 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 295/300 Step: 299 loss : 1.0557 accuracy: 0.5054: 100%|██████████| 46/46 [00:06<00:00,  6.99it/s]\n",
      "epoch: 296/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:02<00:00,  1.23it/s]\n",
      "val_epoch: 296/300 Step: 299 loss : 1.0875 accuracy: 0.4728: 100%|██████████| 46/46 [00:06<00:00,  7.37it/s]\n",
      "epoch: 297/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 297/300 Step: 299 loss : 1.0489 accuracy: 0.5109: 100%|██████████| 46/46 [00:05<00:00,  7.68it/s]\n",
      "epoch: 298/300 Step: 299 loss : 0.5618 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 298/300 Step: 299 loss : 1.0234 accuracy: 0.5380: 100%|██████████| 46/46 [00:06<00:00,  7.37it/s]\n",
      "epoch: 299/300 Step: 299 loss : 0.5619 accuracy: 0.9899: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n",
      "val_epoch: 299/300 Step: 299 loss : 1.0383 accuracy: 0.5217: 100%|██████████| 46/46 [00:06<00:00,  7.01it/s]\n",
      "epoch: 300/300 Step: 299 loss : 0.5617 accuracy: 0.9899: 100%|██████████| 298/298 [04:03<00:00,  1.22it/s]\n",
      "val_epoch: 300/300 Step: 299 loss : 1.0615 accuracy: 0.5000: 100%|██████████| 46/46 [00:06<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Time : 2024-5-9 13:51:0s Time taken : -75420.46495223045\n",
      "[deeplearning End]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "d = datetime.datetime.now()\n",
    "now_time = f\"{d.year}-{d.month}-{d.day} {d.hour}:{d.minute}:{d.second}\"\n",
    "print(f'[deeplearning Start]')\n",
    "print(f'deeplearning Start Time : {now_time}')\n",
    "MIN_loss=5000\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "train_acc_list=[]\n",
    "sig=nn.Sigmoid()\n",
    "val_acc_list=[]\n",
    "MIN_acc=0\n",
    "check_val=1000\n",
    "for epoch in range(300):\n",
    "    train=tqdm(train_dataloader)\n",
    "    count=0\n",
    "    running_loss = 0.0\n",
    "    acc_loss=0\n",
    "    model.train()\n",
    "    for x, y in train:\n",
    "        y = y.float().to(device)\n",
    "        count+=1\n",
    "        x=x.float().to(device)\n",
    "        enable_running_stats(model)\n",
    "        predict = model(x).to(device)\n",
    "        cost = criterion(predict.softmax(dim=1), y.argmax(dim=1)) # cost 구함\n",
    "        acc=accuracy(predict.softmax(dim=1), y.argmax(dim=1))\n",
    "        cost.backward() # cost에 대한 backward 구함\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        disable_running_stats(model)\n",
    "        predict = model(x).to(device)\n",
    "        cost1 = criterion(predict.softmax(dim=1), y.argmax(dim=1)) # cost 구함\n",
    "        cost1.backward() # cost에 대한 backward 구함\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        running_loss += cost.item()\n",
    "        acc_loss+=acc\n",
    "        train.set_description(f\"epoch: {epoch+1}/{300} Step: {count+1} loss : {running_loss/count:.4f} accuracy: {acc_loss/count:.4f}\")\n",
    "    train_loss_list.append((running_loss/count))\n",
    "    train_acc_list.append((acc_loss/count).cpu().detach().numpy())  \n",
    "    val=tqdm(val_dataloader)\n",
    "    path_list=[]\n",
    "    model.eval()\n",
    "    val_count=0\n",
    "    val_running_loss = 0.0\n",
    "    val_acc_loss=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in val:\n",
    "            y = y.to(device).float()\n",
    "            val_count+=1\n",
    "            x=x.to(device).float()\n",
    "            predict = model(x).to(device)\n",
    "            cost = criterion(predict.softmax(dim=1), y.argmax(dim=1)) # cost 구함\n",
    "            acc=accuracy(predict.softmax(dim=1), y.argmax(dim=1))\n",
    "            val_running_loss+=cost.item()\n",
    "            val_acc_loss+=acc\n",
    "            val.set_description(f\"val_epoch: {epoch+1}/{300} Step: {count+1} loss : {val_running_loss/val_count:.4f} accuracy: {val_acc_loss/val_count:.4f}\")\n",
    "        val_loss_list.append((val_running_loss/val_count))\n",
    "        val_acc_list.append((val_acc_loss/val_count).cpu().detach().numpy())  \n",
    "        torch.save(model.state_dict(), '../../model/mteg/attention_MIL/attention_MIL_'+str(epoch)+'.pt')\n",
    "torch.save(model.state_dict(), '../../model/mteg/attention_MIL/attention_MIL.pt')\n",
    "end = time.time()\n",
    "d = datetime.datetime.now()\n",
    "now_time = f\"{d.year}-{d.month}-{d.day} {d.hour}:{d.minute}:{d.second}\"\n",
    "print(f'deeplearning Time : {now_time}s Time taken : {start-end}')\n",
    "print(f'[deeplearning End]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../../model/mteg/attention_eff50_MIL.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y.argmax(dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
