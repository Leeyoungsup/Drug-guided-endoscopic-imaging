{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "import json\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 경고 메시지를 무시하도록 설정\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 경고 메시지를 무시하도록 설정\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "\n",
    "\n",
    "def expand2square(pil_img, background_color):\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        return pil_img\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result\n",
    "\n",
    "\n",
    "def Preprocessing(file_list,dataset_calss, label_data):\n",
    "    start = time.time()\n",
    "    d = datetime.datetime.now()\n",
    "    now_time = f\"{d.year}-{d.month}-{d.day} {d.hour}:{d.minute}:{d.second}\"\n",
    "    print(f'[Preprocessing Start]')\n",
    "    print(f'Preprocessing Start Time : {now_time}')\n",
    "    frame_path = '../../data/mteg_data/lateral_internal/'+dataset_calss+'/'    \n",
    "    for i in tqdm(range(len(file_list))):\n",
    "       \n",
    "        count = 0\n",
    "        vidcap = torchvision.io.read_video(file_list[i])\n",
    "        fps = int(vidcap[2]['video_fps'])\n",
    "        video = np.array(vidcap[0], dtype=np.uint8)\n",
    "        video_crop = np.zeros(\n",
    "            (len(video)-1, video.shape[1], video.shape[2], 3))\n",
    "        for j in range(len(video_crop)):\n",
    "            video_crop[j] = video[j+1]-video[j]\n",
    "        video_crop = video_crop.sum(axis=0)\n",
    "        video_crop = video_crop.sum(axis=2)\n",
    "        video_crop = ((video_crop/video_crop.max())*255).astype(np.uint8)\n",
    "        y1 = np.where(video_crop > 200)[0].min()\n",
    "        y2 = np.where(video_crop > 200)[0].max()\n",
    "        x1 = np.where(video_crop > 200)[1].min()\n",
    "        x2 = np.where(video_crop > 200)[1].max()\n",
    "        video_name = os.path.basename(file_list[i])\n",
    "        dst_label = label_data.loc[label_data[\"File Name\"] == video_name]\n",
    "        wake = str(dst_label['구분값'].item())\n",
    "        Serial_Number = str(dst_label['일련번호'].item())\n",
    "        file_name = Serial_Number+wake\n",
    "        createDirectory(frame_path+file_name)\n",
    "        for k in range(0, len(video), fps//5):\n",
    "            img = Image.fromarray(video[k, y1:y2, x1:x2])\n",
    "            img.resize((256, 256)).save(\n",
    "                frame_path+file_name+\"/%06d.jpg\" % count)\n",
    "            count += 1\n",
    "    \n",
    "    end = time.time()\n",
    "    d = datetime.datetime.now()\n",
    "    now_time = f\"{d.year}-{d.month}-{d.day} {d.hour}:{d.minute}:{d.second}\"\n",
    "    print(f'Preprocessing Time : {now_time}s Time taken : {end-start}')\n",
    "    print(f'[Preprocessing End]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "train_label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "test_label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "val_label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "classes = ['Oropharynx_posterior_lateral_walls', 'Tongue_Base', 'Epiglottis']\n",
    "label_list=glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/train/*.json')\n",
    "train_count=0\n",
    "test_count=0\n",
    "val_count=0\n",
    "for i in range(len(label_list)):\n",
    "    with open(label_list[i], 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    f.close()\n",
    "    if json_data['metas']['position']!='lateral':\n",
    "        try:\n",
    "            separation_value= json_data['videos']['id'][json_data['videos']['id'].find('_')-1]\n",
    "            serial_number=json_data['videos']['id'][:json_data['videos']['id'].find('_')-1]\n",
    "            causes_of_OTE=json_data['videos']['id']\n",
    "            label_data.loc[train_count]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "            train_label_data.loc[train_count]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "            train_count+=1\n",
    "        except:\n",
    "            print(json_data['videos']['id'])\n",
    "train_label_data.to_csv('../../data/mteg_data/lateral_internal/train_label.csv',index=False)\n",
    "label_list=glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/*.json')\n",
    "for i in range(len(label_list)):\n",
    "    with open(label_list[i], 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    f.close()\n",
    "    if json_data['metas']['position']!='lateral':\n",
    "        try:\n",
    "            separation_value= json_data['videos']['id'][json_data['videos']['id'].find('_')-1]\n",
    "            serial_number=json_data['videos']['id'][:json_data['videos']['id'].find('_')-1]\n",
    "            causes_of_OTE=json_data['videos']['id']\n",
    "            label_data.loc[train_count+test_count]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "            test_label_data.loc[test_count]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "            test_count+=1\n",
    "        except:\n",
    "            print(json_data['videos']['id'])\n",
    "test_label_data.to_csv('../../data/mteg_data/lateral_internal/test_label.csv',index=False)\n",
    "label_list=glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/val/*.json')\n",
    "for i in range(len(label_list)):\n",
    "    with open(label_list[i], 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    f.close()\n",
    "    if json_data['metas']['position']!='lateral':\n",
    "        try:\n",
    "            separation_value= json_data['videos']['id'][json_data['videos']['id'].find('_')-1]\n",
    "            serial_number=json_data['videos']['id'][:json_data['videos']['id'].find('_')-1]\n",
    "            causes_of_OTE=json_data['videos']['id']\n",
    "            label_data.loc[train_count+test_count+val_count]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "            val_label_data.loc[val_count]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "            val_count+=1\n",
    "        except:\n",
    "            print(json_data['videos']['id'])\n",
    "val_label_data.to_csv('../../data/mteg_data/lateral_internal/val_label.csv',index=False)\n",
    "label_data.to_csv('../../data/mteg_data/lateral_internal/label.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv('../../data/mteg_data/lateral_internal/label.csv')\n",
    "train_label_data = pd.read_csv('../../data/mteg_data/lateral_internal/train_label.csv')\n",
    "test_label_data = pd.read_csv('../../data/mteg_data/lateral_internal/test_label.csv')\n",
    "val_label_data = pd.read_csv('../../data/mteg_data/lateral_internal/val_label.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Preprocessing Start]\n",
      "Preprocessing Start Time : 2024-5-14 15:32:5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607553ed1d844199952eb799c2670da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Time : 2024-5-14 15:36:38s Time taken : 272.7786474227905\n",
      "[Preprocessing End]\n",
      "[Preprocessing Start]\n",
      "Preprocessing Start Time : 2024-5-14 15:36:38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4b0b260a4e4609bd3ef0853794d881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Time : 2024-5-14 15:42:4s Time taken : 326.619745016098\n",
      "[Preprocessing End]\n"
     ]
    }
   ],
   "source": [
    "file_list = []\n",
    "for i in range(len(train_label_data)):\n",
    "    file_list.append('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/train/'+train_label_data['File Name'][i])\n",
    "Preprocessing(file_list,'train', train_label_data)\n",
    "file_list = []\n",
    "for i in range(len(test_label_data)):\n",
    "    file_list.append('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/'+test_label_data['File Name'][i])\n",
    "Preprocessing(file_list,'test', test_label_data)\n",
    "file_list = []\n",
    "for i in range(len(val_label_data)):\n",
    "    file_list.append('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/val/'+val_label_data['File Name'][i])\n",
    "Preprocessing(file_list,'val', val_label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        10111431_94_OTEclip.mp4\n",
       "3        10151320_99_OTEclip.mp4\n",
       "4       10161180_100_OTEclip.mp4\n",
       "5        10161183_92_OTEclip.mp4\n",
       "8        10191620_99_OTEclip.mp4\n",
       "                  ...           \n",
       "1188        50521511_OTEclip.mp4\n",
       "1189        50531341_OTEclip.mp4\n",
       "1190        50541481_OTEclip.mp4\n",
       "1191        50301291_OTEclip.mp4\n",
       "1192        50311471_OTEclip.mp4\n",
       "Name: File Name, Length: 842, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_data['File Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10111431_94_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10151320_99_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10161180_100_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10161183_92_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10191620_99_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10202530_99_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10202533_97_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10221361_93_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10221363_98_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10231601_88_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10252481_92_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10252483_95_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10272561_85_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10302551_95_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10302553_99_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10322331_95_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10332443_71_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10341351_94_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10341353_98_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10351251_96_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10351253_99_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10371521_76_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10372723_95_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10391421_87_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10401551_95_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10401553_97_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10412551_95_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10421341_94_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10421343_99_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10431313_100_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10441603_97_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10451331_100_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10451333_100_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10461303_100_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10471581_88_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10471583_96_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10491481_89_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10491483_95_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10501551_95_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10501553_100_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10512501_85_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10512503_95_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10541431_93_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10541433_94_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10552691_95_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10552693_93_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10562411_96_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10591301_95_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10591303_96_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10611391_95_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10622581_91_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10631491_96_OTEclip.mp4',\n",
       " '../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/10631493_97_OTEclip.mp4']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
