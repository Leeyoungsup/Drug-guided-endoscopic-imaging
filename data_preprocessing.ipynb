{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "import json\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 경고 메시지를 무시하도록 설정\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 경고 메시지를 무시하도록 설정\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "\n",
    "\n",
    "def expand2square(pil_img, background_color):\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        return pil_img\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result\n",
    "\n",
    "\n",
    "def Preprocessing(file_list,dataset_calss, label_data):\n",
    "    start = time.time()\n",
    "    d = datetime.datetime.now()\n",
    "    now_time = f\"{d.year}-{d.month}-{d.day} {d.hour}:{d.minute}:{d.second}\"\n",
    "    print(f'[Preprocessing Start]')\n",
    "    print(f'Preprocessing Start Time : {now_time}')\n",
    "    frame_path = '../../data/mteg_data/internal/'+dataset_calss+'/'    \n",
    "    for i in tqdm(range(len(file_list))):\n",
    "       \n",
    "        count = 0\n",
    "        vidcap = torchvision.io.read_video(file_list[i])\n",
    "        fps = int(vidcap[2]['video_fps'])\n",
    "        video = np.array(vidcap[0], dtype=np.uint8)\n",
    "        video_crop = np.zeros(\n",
    "            (len(video)-1, video.shape[1], video.shape[2], 3))\n",
    "        for j in range(len(video_crop)):\n",
    "            video_crop[j] = video[j+1]-video[j]\n",
    "        video_crop = video_crop.sum(axis=0)\n",
    "        video_crop = video_crop.sum(axis=2)\n",
    "        video_crop = ((video_crop/video_crop.max())*255).astype(np.uint8)\n",
    "        y1 = np.where(video_crop > 200)[0].min()\n",
    "        y2 = np.where(video_crop > 200)[0].max()\n",
    "        x1 = np.where(video_crop > 200)[1].min()\n",
    "        x2 = np.where(video_crop > 200)[1].max()\n",
    "        video_name = os.path.basename(file_list[i])\n",
    "        dst_label = label_data.loc[label_data[\"File Name\"] == video_name]\n",
    "        wake = str(dst_label['구분값'].item())\n",
    "        Serial_Number = str(dst_label['일련번호'].item())\n",
    "        file_name = Serial_Number+wake\n",
    "        createDirectory(frame_path+file_name)\n",
    "        for k in range(0, len(video), fps//5):\n",
    "            img = Image.fromarray(video[k, y1:y2, x1:x2])\n",
    "            img.resize((256, 256)).save(\n",
    "                frame_path+file_name+\"/%06d.jpg\" % count)\n",
    "            count += 1\n",
    "    \n",
    "    end = time.time()\n",
    "    d = datetime.datetime.now()\n",
    "    now_time = f\"{d.year}-{d.month}-{d.day} {d.hour}:{d.minute}:{d.second}\"\n",
    "    print(f'Preprocessing Time : {now_time}s Time taken : {end-start}')\n",
    "    print(f'[Preprocessing End]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "train_label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "test_label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "val_label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "classes = ['Oropharynx_posterior_lateral_walls', 'Tongue_Base', 'Epiglottis']\n",
    "label_list=glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/train/*.json')\n",
    "for i in range(len(label_list)):\n",
    "    with open(label_list[i], 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    f.close()\n",
    "    try:\n",
    "        separation_value= json_data['videos']['id'][json_data['videos']['id'].find('_')-1]\n",
    "        serial_number=json_data['videos']['id'][:json_data['videos']['id'].find('_')-1]\n",
    "        causes_of_OTE=json_data['videos']['id']\n",
    "        label_data.loc[i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "        train_label_data.loc[i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "    except:\n",
    "        print(json_data['videos']['id'])\n",
    "train_label_data.to_csv('../../data/mteg_data/internal/train_label.csv',index=False)\n",
    "label_list=glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/*.json')\n",
    "for i in range(len(label_list)):\n",
    "    with open(label_list[i], 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    f.close()\n",
    "    try:\n",
    "        separation_value= json_data['videos']['id'][json_data['videos']['id'].find('_')-1]\n",
    "        serial_number=json_data['videos']['id'][:json_data['videos']['id'].find('_')-1]\n",
    "        causes_of_OTE=json_data['videos']['id']\n",
    "        label_data.loc[len(train_label_data)+i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "        test_label_data.loc[i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "    except:\n",
    "        print(json_data['videos']['id'])\n",
    "test_label_data.to_csv('../../data/mteg_data/internal/test_label.csv',index=False)\n",
    "label_list=glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/val/*.json')\n",
    "for i in range(len(label_list)):\n",
    "    with open(label_list[i], 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    f.close()\n",
    "    try:\n",
    "        separation_value= json_data['videos']['id'][json_data['videos']['id'].find('_')-1]\n",
    "        serial_number=json_data['videos']['id'][:json_data['videos']['id'].find('_')-1]\n",
    "        causes_of_OTE=json_data['videos']['id']\n",
    "        label_data.loc[len(train_label_data)+i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "        val_label_data.loc[i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "    except:\n",
    "        print(json_data['videos']['id'])\n",
    "val_label_data.to_csv('../../data/mteg_data/internal/val_label.csv',index=False)\n",
    "label_data.to_csv('../../data/mteg_data/internal/label.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>구분값</th>\n",
       "      <th>일련번호</th>\n",
       "      <th>OTE 원인</th>\n",
       "      <th>File Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1752149</td>\n",
       "      <td>1</td>\n",
       "      <td>17521492_95_OTEclip.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1755130</td>\n",
       "      <td>1</td>\n",
       "      <td>17551303_98_OTEclip.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1761257</td>\n",
       "      <td>1</td>\n",
       "      <td>17612572_96_OTEclip.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1771129</td>\n",
       "      <td>1</td>\n",
       "      <td>17711293_77_OTEclip.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1781165</td>\n",
       "      <td>2</td>\n",
       "      <td>17811653_94_OTEclip.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2</td>\n",
       "      <td>4372154</td>\n",
       "      <td>2</td>\n",
       "      <td>43721542_94_OTEclip.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>4379158</td>\n",
       "      <td>1</td>\n",
       "      <td>43791581_87_OTEclip.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2</td>\n",
       "      <td>4380150</td>\n",
       "      <td>1</td>\n",
       "      <td>43801502_88_OTEclip.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2</td>\n",
       "      <td>4381147</td>\n",
       "      <td>2</td>\n",
       "      <td>43811472_95_OTEclip.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2</td>\n",
       "      <td>11000125</td>\n",
       "      <td>3</td>\n",
       "      <td>110001252_85_OTEclip.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    구분값      일련번호  OTE 원인                 File Name\n",
       "0     2   1752149       1   17521492_95_OTEclip.mp4\n",
       "1     3   1755130       1   17551303_98_OTEclip.mp4\n",
       "2     2   1761257       1   17612572_96_OTEclip.mp4\n",
       "3     3   1771129       1   17711293_77_OTEclip.mp4\n",
       "4     3   1781165       2   17811653_94_OTEclip.mp4\n",
       "..  ...       ...     ...                       ...\n",
       "75    2   4372154       2   43721542_94_OTEclip.mp4\n",
       "76    1   4379158       1   43791581_87_OTEclip.mp4\n",
       "77    2   4380150       1   43801502_88_OTEclip.mp4\n",
       "78    2   4381147       2   43811472_95_OTEclip.mp4\n",
       "79    2  11000125       3  110001252_85_OTEclip.mp4\n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv('../../data/mteg_data/internal/label.csv')\n",
    "train_label_data = pd.read_csv('../../data/mteg_data/internal/train_label.csv')\n",
    "test_label_data = pd.read_csv('../../data/mteg_data/internal/test_label.csv')\n",
    "val_label_data = pd.read_csv('../../data/mteg_data/internal/val_label.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Preprocessing Start]\n",
      "Preprocessing Start Time : 2024-5-8 11:56:26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f1c1152b7847da9d94220c48a996e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Time : 2024-5-8 13:13:23s Time taken : 4616.715015411377\n",
      "[Preprocessing End]\n",
      "[Preprocessing Start]\n",
      "Preprocessing Start Time : 2024-5-8 13:13:23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5696012ac15d442e8e555cddddd136c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Time : 2024-5-8 13:18:50s Time taken : 326.9929370880127\n",
      "[Preprocessing End]\n",
      "[Preprocessing Start]\n",
      "Preprocessing Start Time : 2024-5-8 13:18:50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b0afbb9cab4d9b84230f898e76af3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Time : 2024-5-8 13:26:56s Time taken : 486.49016284942627\n",
      "[Preprocessing End]\n"
     ]
    }
   ],
   "source": [
    "file_list = glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/train/*.mp4')\n",
    "Preprocessing(file_list,'train', train_label_data)\n",
    "file_list = glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/test/*.mp4')\n",
    "Preprocessing(file_list,'test', test_label_data)\n",
    "file_list = glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data_internal/val/*.mp4')\n",
    "Preprocessing(file_list,'val', val_label_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
