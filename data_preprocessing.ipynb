{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "import json\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 경고 메시지를 무시하도록 설정\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 경고 메시지를 무시하도록 설정\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "\n",
    "\n",
    "def expand2square(pil_img, background_color):\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        return pil_img\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result\n",
    "\n",
    "\n",
    "def Preprocessing(file_list,dataset_calss, label_data):\n",
    "    start = time.time()\n",
    "    d = datetime.datetime.now()\n",
    "    now_time = f\"{d.year}-{d.month}-{d.day} {d.hour}:{d.minute}:{d.second}\"\n",
    "    print(f'[Preprocessing Start]')\n",
    "    print(f'Preprocessing Start Time : {now_time}')\n",
    "    frame_path = '../../data/mteg_data/frame/'+dataset_calss+'/'    \n",
    "    for i in tqdm(range(len(file_list))):\n",
    "       \n",
    "        count = 0\n",
    "        vidcap = torchvision.io.read_video(file_list[i])\n",
    "        fps = int(vidcap[2]['video_fps'])\n",
    "        video = np.array(vidcap[0], dtype=np.uint8)\n",
    "        video_crop = np.zeros(\n",
    "            (len(video)-1, video.shape[1], video.shape[2], 3))\n",
    "        for j in range(len(video_crop)):\n",
    "            video_crop[j] = video[j+1]-video[j]\n",
    "        video_crop = video_crop.sum(axis=0)\n",
    "        video_crop = video_crop.sum(axis=2)\n",
    "        video_crop = ((video_crop/video_crop.max())*255).astype(np.uint8)\n",
    "        y1 = np.where(video_crop > 100)[0].min()\n",
    "        y2 = np.where(video_crop > 100)[0].max()\n",
    "        x1 = np.where(video_crop > 100)[1].min()\n",
    "        x2 = np.where(video_crop > 100)[1].max()\n",
    "        video_name = os.path.basename(file_list[i])\n",
    "        dst_label = label_data.loc[label_data[\"File Name\"] == video_name]\n",
    "        wake = str(dst_label['구분값'].item())\n",
    "        Serial_Number = str(dst_label['일련번호'].item())\n",
    "        file_name = Serial_Number+wake\n",
    "        createDirectory(frame_path+file_name)\n",
    "        for k in range(0, len(video), fps//5):\n",
    "            img = Image.fromarray(video[k, y1:y2, x1:x2])\n",
    "            im_new = expand2square(img, (0, 0, 0))\n",
    "            im_new.resize((256, 256)).save(\n",
    "                frame_path+file_name+\"/%06d.jpg\" % count)\n",
    "            count += 1\n",
    "    \n",
    "    end = time.time()\n",
    "    d = datetime.datetime.now()\n",
    "    now_time = f\"{d.year}-{d.month}-{d.day} {d.hour}:{d.minute}:{d.second}\"\n",
    "    print(f'Preprocessing Time : {now_time}s Time taken : {end-start}')\n",
    "    print(f'[Preprocessing End]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m label_list\u001b[38;5;241m=\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/train/*.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(label_list)):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      9\u001b[0m         json_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     10\u001b[0m     f\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/_bootlocale.py:33\u001b[0m, in \u001b[0;36mgetpreferredencoding\u001b[0;34m(do_setlocale)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m locale\u001b[38;5;241m.\u001b[39mgetpreferredencoding(do_setlocale)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetpreferredencoding\u001b[39m(do_setlocale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m do_setlocale\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mutf8_mode:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "train_label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "test_label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "val_label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "classes = ['Oropharynx_posterior_lateral_walls', 'Tongue_Base', 'Epiglottis']\n",
    "label_list=glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/train/*.json')\n",
    "for i in range(len(label_list)):\n",
    "    with open(label_list[i], 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    f.close()\n",
    "    separation_value= json_data['videos']['id'][json_data['videos']['id'].find('_')-1:json_data['videos']['id'].find('_')]\n",
    "    serial_number=json_data['videos']['id'][:json_data['videos']['id'].find('_')-1]\n",
    "    causes_of_OTE=json_data['videos']['id']\n",
    "    label_data.loc[i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "    train_label_data.loc[i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "train_label_data.to_csv('../../data/mteg_data/train_label.csv',index=False)\n",
    "label_list=glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/test/*.json')\n",
    "for i in range(len(label_list)):\n",
    "    with open(label_list[i], 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    f.close()\n",
    "    separation_value= json_data['videos']['id'][json_data['videos']['id'].find('_')-1:json_data['videos']['id'].find('_')]\n",
    "    serial_number=json_data['videos']['id'][:json_data['videos']['id'].find('_')-1]\n",
    "    causes_of_OTE=json_data['videos']['id']\n",
    "    label_data.loc[i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "    test_label_data.loc[i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "test_label_data.to_csv('../../data/mteg_data/test_label.csv',index=False)\n",
    "label_list=glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/val/*.json')\n",
    "for i in range(len(label_list)):\n",
    "    with open(label_list[i], 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    f.close()\n",
    "    separation_value= json_data['videos']['id'][json_data['videos']['id'].find('_')-1:json_data['videos']['id'].find('_')]\n",
    "    serial_number=json_data['videos']['id'][:json_data['videos']['id'].find('_')-1]\n",
    "    causes_of_OTE=json_data['videos']['id']\n",
    "    label_data.loc[i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "    val_label_data.loc[i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "val_label_data.to_csv('../../data/mteg_data/val_label.csv',index=False)\n",
    "label_data.to_csv('../../data/mteg_data/label.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv('../../data/mteg_data/label.csv')\n",
    "train_label_data = pd.read_csv('../../data/mteg_data/train_label.csv')\n",
    "test_label_data = pd.read_csv('../../data/mteg_data/test_label.csv')\n",
    "val_label_data = pd.read_csv('../../data/mteg_data/val_label.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Preprocessing Start]\n",
      "Preprocessing Start Time : 2024-4-23 16:25:11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b752d69115543dbb47344494c085563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "BlockingIOError",
     "evalue": "[Errno 11] Resource temporarily unavailable: '../../data/mteg_data/frame/train/10191620/000063.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBlockingIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_list \u001b[38;5;241m=\u001b[39m glob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/train/*.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mPreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_list\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m file_list \u001b[38;5;241m=\u001b[39m glob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/test/*.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m Preprocessing(file_list,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, test_label_data)\n",
      "Cell \u001b[0;32mIn[2], line 74\u001b[0m, in \u001b[0;36mPreprocessing\u001b[0;34m(file_list, dataset_calss, label_data)\u001b[0m\n\u001b[1;32m     72\u001b[0m         img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(video[k, y1:y2, x1:x2])\n\u001b[1;32m     73\u001b[0m         im_new \u001b[38;5;241m=\u001b[39m expand2square(img, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 74\u001b[0m         \u001b[43mim_new\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mframe_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m%06d\u001b[39;49;00m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m         count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     78\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/PIL/Image.py:2436\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2434\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2436\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2439\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[0;31mBlockingIOError\u001b[0m: [Errno 11] Resource temporarily unavailable: '../../data/mteg_data/frame/train/10191620/000063.jpg'"
     ]
    }
   ],
   "source": [
    "file_list = glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/train/*.mp4')\n",
    "Preprocessing(file_list,'train', train_label_data)\n",
    "file_list = glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/test/*.mp4')\n",
    "Preprocessing(file_list,'test', test_label_data)\n",
    "file_list = glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/val/*.mp4')\n",
    "Preprocessing(file_list,'val', val_label_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
