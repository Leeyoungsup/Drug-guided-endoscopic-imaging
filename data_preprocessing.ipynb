{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "import json\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 경고 메시지를 무시하도록 설정\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 경고 메시지를 무시하도록 설정\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "\n",
    "\n",
    "def expand2square(pil_img, background_color):\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        return pil_img\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result\n",
    "\n",
    "\n",
    "def Preprocessing(file_list,dataset_calss, label_data):\n",
    "    start = time.time()\n",
    "    d = datetime.datetime.now()\n",
    "    now_time = f\"{d.year}-{d.month}-{d.day} {d.hour}:{d.minute}:{d.second}\"\n",
    "    print(f'[Preprocessing Start]')\n",
    "    print(f'Preprocessing Start Time : {now_time}')\n",
    "    frame_path = '../../data/mteg_data/frame/'+dataset_calss+'/'    \n",
    "    for i in tqdm(range(len(file_list))):\n",
    "       \n",
    "        count = 0\n",
    "        vidcap = torchvision.io.read_video(file_list[i])\n",
    "        fps = int(vidcap[2]['video_fps'])\n",
    "        video = np.array(vidcap[0], dtype=np.uint8)\n",
    "        video_crop = np.zeros(\n",
    "            (len(video)-1, video.shape[1], video.shape[2], 3))\n",
    "        for j in range(len(video_crop)):\n",
    "            video_crop[j] = video[j+1]-video[j]\n",
    "        video_crop = video_crop.sum(axis=0)\n",
    "        video_crop = video_crop.sum(axis=2)\n",
    "        video_crop = ((video_crop/video_crop.max())*255).astype(np.uint8)\n",
    "        y1 = np.where(video_crop > 100)[0].min()\n",
    "        y2 = np.where(video_crop > 100)[0].max()\n",
    "        x1 = np.where(video_crop > 100)[1].min()\n",
    "        x2 = np.where(video_crop > 100)[1].max()\n",
    "        video_name = os.path.basename(file_list[i])\n",
    "        dst_label = label_data.loc[label_data[\"File Name\"] == video_name]\n",
    "        wake = str(dst_label['구분값'].item())\n",
    "        Serial_Number = str(dst_label['일련번호'].item())\n",
    "        file_name = Serial_Number+wake\n",
    "        createDirectory(frame_path+file_name)\n",
    "        for k in range(0, len(video), fps//5):\n",
    "            img = Image.fromarray(video[k, y1:y2, x1:x2])\n",
    "            im_new = expand2square(img, (0, 0, 0))\n",
    "            im_new.resize((256, 256)).save(\n",
    "                frame_path+file_name+\"/%06d.jpg\" % count)\n",
    "            count += 1\n",
    "    \n",
    "    end = time.time()\n",
    "    d = datetime.datetime.now()\n",
    "    now_time = f\"{d.year}-{d.month}-{d.day} {d.hour}:{d.minute}:{d.second}\"\n",
    "    print(f'Preprocessing Time : {now_time}s Time taken : {end-start}')\n",
    "    print(f'[Preprocessing End]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "train_label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "test_label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "val_label_data = pd.DataFrame(columns=['구분값', '일련번호', 'OTE 원인','File Name'])\n",
    "classes = ['Oropharynx_posterior_lateral_walls', 'Tongue_Base', 'Epiglottis']\n",
    "label_list=glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/train/*.json')\n",
    "for i in range(len(label_list)):\n",
    "    with open(label_list[i], 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    f.close()\n",
    "    separation_value= json_data['videos']['id'][json_data['videos']['id'].find('_')-1]\n",
    "    serial_number=json_data['videos']['id'][:json_data['videos']['id'].find('_')-1]\n",
    "    causes_of_OTE=json_data['videos']['id']\n",
    "    label_data.loc[i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "    train_label_data.loc[i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "train_label_data.to_csv('../../data/mteg_data/train_label.csv',index=False)\n",
    "label_list=glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/test/*.json')\n",
    "for i in range(len(label_list)):\n",
    "    with open(label_list[i], 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    f.close()\n",
    "    separation_value= json_data['videos']['id'][json_data['videos']['id'].find('_')-1]\n",
    "    serial_number=json_data['videos']['id'][:json_data['videos']['id'].find('_')-1]\n",
    "    causes_of_OTE=json_data['videos']['id']\n",
    "    label_data.loc[len(train_label_data)+i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "    test_label_data.loc[i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "test_label_data.to_csv('../../data/mteg_data/test_label.csv',index=False)\n",
    "label_list=glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/val/*.json')\n",
    "for i in range(len(label_list)):\n",
    "    with open(label_list[i], 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    f.close()\n",
    "    separation_value= json_data['videos']['id'][json_data['videos']['id'].find('_')-1]\n",
    "    serial_number=json_data['videos']['id'][:json_data['videos']['id'].find('_')-1]\n",
    "    causes_of_OTE=json_data['videos']['id']\n",
    "    label_data.loc[len(train_label_data)+len(test_label_data)+i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "    val_label_data.loc[i]=[int(separation_value),int(serial_number),classes.index(json_data['metas']['cause'])+1,json_data['videos']['filename']]\n",
    "val_label_data.to_csv('../../data/mteg_data/val_label.csv',index=False)\n",
    "label_data.to_csv('../../data/mteg_data/label.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv('../../data/mteg_data/label.csv')\n",
    "train_label_data = pd.read_csv('../../data/mteg_data/train_label.csv')\n",
    "test_label_data = pd.read_csv('../../data/mteg_data/test_label.csv')\n",
    "val_label_data = pd.read_csv('../../data/mteg_data/val_label.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Preprocessing Start]\n",
      "Preprocessing Start Time : 2024-4-23 16:42:2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac637705ae248bdb20025ce120cfdc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Time : 2024-4-23 18:30:51s Time taken : 6528.5891144275665\n",
      "[Preprocessing End]\n",
      "[Preprocessing Start]\n",
      "Preprocessing Start Time : 2024-4-23 18:30:51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc069260f874dba92d8d0c217552dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Time : 2024-4-23 18:48:49s Time taken : 1077.4641826152802\n",
      "[Preprocessing End]\n",
      "[Preprocessing Start]\n",
      "Preprocessing Start Time : 2024-4-23 18:48:49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2a6a8d342f47f6ba1e6c479eaadc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Time : 2024-4-23 19:1:56s Time taken : 787.0273213386536\n",
      "[Preprocessing End]\n"
     ]
    }
   ],
   "source": [
    "file_list = glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/train/*.mp4')\n",
    "Preprocessing(file_list,'train', train_label_data)\n",
    "file_list = glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/test/*.mp4')\n",
    "Preprocessing(file_list,'test', test_label_data)\n",
    "file_list = glob('../../../../YS_Baik/5.NIA_42/02_2_classification_gachon/01_data/val/*.mp4')\n",
    "Preprocessing(file_list,'val', val_label_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
